"""
Sage Stream Service

åŸºäº Sage æ¡†æ¶çš„æ™ºèƒ½ä½“æµå¼æœåŠ¡
æä¾›ç®€æ´çš„ HTTP API å’Œ Server-Sent Events (SSE) å®æ—¶é€šä¿¡
ä¸åšä»»ä½•çš„é…ç½®ä»¥åŠè®¾ç½®çš„ç¼“å­˜ï¼Œæ‰€æœ‰çš„é…ç½®éƒ½é€šè¿‡æ¥å£ä¼ å…¥
"""

from ctypes import Union
from math import log
import os
import sys
import json
import uuid
import asyncio
import traceback
import time
from pathlib import Path
from typing import List, Dict, Any, Optional, AsyncGenerator, Union
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Depends, status, Response, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse, FileResponse
from pydantic import BaseModel
import uvicorn

# æ·»åŠ  Sage é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
print(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from sagents.sagents import SAgent
from sagents.tool.tool_manager import ToolManager
from sagents.tool.tool_proxy import ToolProxy
from sagents.utils.logger import logger
from openai import OpenAI
from sagents.context.session_context import SessionStatus,get_session_context


import argparse

parser = argparse.ArgumentParser(description="Sage Stream Service")
parser.add_argument("--default_llm_api_key", required=True, help="é»˜è®¤LLM API Key")
parser.add_argument("--default_llm_api_base_url", required=True, help="é»˜è®¤LLM API Base")
parser.add_argument("--default_llm_model_name", required=True, help="é»˜è®¤LLM API Model")
parser.add_argument("--default_llm_max_tokens", default=4096, type=int, help="é»˜è®¤LLM API Max Tokens")
parser.add_argument("--default_llm_temperature", default=0.3, type=float, help="é»˜è®¤LLM API Temperature")
parser.add_argument("--host", default="0.0.0.0", help="Server Host")
parser.add_argument("--port", default=8001, type=int, help="Server Port")

parser.add_argument("--mcp-config", default="mcp_setting.json", help="MCPé…ç½®æ–‡ä»¶è·¯å¾„")
parser.add_argument("--workspace", default="sage_demo_workspace", help="å·¥ä½œç©ºé—´ç›®å½•")
parser.add_argument("--logs-dir", default="logs", help="æ—¥å¿—ç›®å½•")
parser.add_argument("--preset_running_config", default="", help="é¢„è®¾é…ç½®ï¼Œsystem_contextï¼Œä»¥åŠworkflowï¼Œä¸æ¥å£ä¸­ä¼ è¿‡æ¥çš„åˆå¹¶ä½¿ç”¨")
parser.add_argument("--memory_root", default=None, help="è®°å¿†å­˜å‚¨æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼‰")
parser.add_argument("--daemon", action="store_true", help="ä»¥å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼è¿è¡Œ")
parser.add_argument("--pid-file", default="sage_stream.pid", help="PIDæ–‡ä»¶è·¯å¾„")

server_args = parser.parse_args()
if server_args.workspace:
    server_args.workspace = os.path.abspath(server_args.workspace)
os.environ['PREFIX_FILE_WORKSPACE'] = server_args.workspace if server_args.workspace.endswith('/') else server_args.workspace+'/'

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    await initialize_system(server_args)
    yield
    # å…³é—­æ—¶æ¸…ç†
    await cleanup_system()

# è®¾ç½®é…ç½®æ–‡ä»¶è·¯å¾„ç¯å¢ƒå˜é‡
os.environ['SAGE_MCP_CONFIG_PATH'] = server_args.mcp_config
# FastAPI åº”ç”¨
app = FastAPI(
    title="Sage Stream Service",
    description="åŸºäº Sage æ¡†æ¶çš„æ™ºèƒ½ä½“æµå¼æœåŠ¡",
    version="1.0.0",
    lifespan=lifespan
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# æ ¸å¿ƒæœåŠ¡ç±»
class SageStreamService:
    """
    Sage æµå¼æœåŠ¡ç±»
    
    æä¾›åŸºäº Sage æ¡†æ¶çš„æ™ºèƒ½ä½“æµå¼æœåŠ¡åŠŸèƒ½
    """
    
    def __init__(self, model: Optional[OpenAI] = None, 
                        model_config: Optional[Dict[str, Any]] = None, 
                        tool_manager: Optional[Union[ToolManager, ToolProxy]] = None, 
                        preset_running_config: Optional[Dict[str, Any]] = None,
                        workspace: Optional[str] = None,
                        memory_root: Optional[str] = None):
        """
        åˆå§‹åŒ–æœåŠ¡
        
        Args:
            model: OpenAI å®¢æˆ·ç«¯å®ä¾‹
            model_config: æ¨¡å‹é…ç½®å­—å…¸
            tool_manager: å·¥å…·ç®¡ç†å™¨å®ä¾‹
        """
        self.preset_running_config = preset_running_config
        self.preset_system_context = None
        if 'system_context' in self.preset_running_config:
            self.preset_system_context = self.preset_running_config['system_context']
        self.preset_available_workflows =None
        if 'available_workflows' in self.preset_running_config:
            self.preset_available_workflows = self.preset_running_config['available_workflows']
        if "system_prefix" in self.preset_running_config:
            self.preset_system_prefix = self.preset_running_config['system_prefix']
        else:
            self.preset_system_prefix = "You are a helpful AI assistant."

        # workspace æœ‰å¯èƒ½æ˜¯ç›¸å¯¹è·¯å¾„
        if workspace:
            workspace = os.path.abspath(workspace)

        # åˆ›å»º Sage AgentController å®ä¾‹
        self.sage_controller = SAgent(
            model=model,
            model_config=model_config,
            system_prefix=self.preset_system_prefix,
            workspace=workspace if workspace.endswith('/') else workspace+'/',
            memory_root=memory_root
        )
        self.tool_manager = tool_manager
        logger.info("SageStreamService åˆå§‹åŒ–å®Œæˆ")
    
    async def process_stream(self, messages, session_id=None, user_id=None, deep_thinking=None, 
                           max_loop_count=None, multi_agent=None,more_suggest=False,
                            system_context:Dict=None, 
                           available_workflows: Dict=None):
        """å¤„ç†æµå¼èŠå¤©è¯·æ±‚"""
        logger.info(f"ğŸš€ SageStreamService.process_stream å¼€å§‹ï¼Œä¼šè¯ID: {session_id}")
        logger.info(f"ğŸ“ å‚æ•°: deep_thinking={deep_thinking}, multi_agent={multi_agent}, messages_count={len(messages)}")
        if isinstance(deep_thinking, str):
            if deep_thinking == 'auto':
                deep_thinking = None
            if deep_thinking == 'off':
                deep_thinking = False
            if deep_thinking == 'on':
                deep_thinking = True
        if isinstance(multi_agent, str):
            if multi_agent == 'auto':
                multi_agent = None
            if multi_agent == 'off':
                multi_agent = False
            if multi_agent == 'on':
                multi_agent = True
        
        
        # å¦‚æœ self.preset_system_context ä¸æ˜¯ç©ºï¼Œå°†self.preset_system_context çš„å†…å®¹ï¼Œæ›´æ–°åˆ° system_contextï¼Œä¸æ˜¯èµ‹å€¼ï¼Œè¦æ£€æŸ¥ä¸€ä¸‹system_context æ˜¯ä¸æ˜¯ç©º
        if self.preset_system_context:
            if system_context:
                system_context.update(self.preset_system_context)
            else:
                system_context = self.preset_system_context
        # å¦‚æœ self.preset_available_workflows ä¸æ˜¯ç©ºï¼Œå°†self.preset_available_workflows çš„å†…å®¹ï¼Œæ›´æ–°åˆ° available_workflowsï¼Œä¸æ˜¯èµ‹å€¼
        if self.preset_available_workflows:
            if available_workflows:
                available_workflows.update(self.preset_available_workflows)
            else:
                available_workflows = self.preset_available_workflows

        try:
            logger.info("ğŸ”„ å‡†å¤‡è°ƒç”¨ sage_controller.run_stream...")
            
            # ç›´æ¥è°ƒç”¨åŒæ­¥çš„ run_stream æ–¹æ³•
            stream_result = self.sage_controller.run_stream(
                input_messages=messages,
                tool_manager=self.tool_manager,
                session_id=session_id,
                user_id=user_id,
                deep_thinking=deep_thinking,
                max_loop_count=max_loop_count,
                multi_agent=multi_agent,
                more_suggest = more_suggest,
                system_context=system_context,
                available_workflows=available_workflows
            )
            
            logger.info("âœ… run_stream è°ƒç”¨æˆåŠŸï¼Œå¼€å§‹å¤„ç†ç»“æœ...")
            
            # å¤„ç†è¿”å›çš„ç”Ÿæˆå™¨
            chunk_count = 0
            for chunk in stream_result:
                chunk_count += 1
                # logger.info(f"ğŸ“¦ å¤„ç†ç¬¬ {chunk_count} ä¸ªå—ï¼ŒåŒ…å« {len(chunk)} æ¡æ¶ˆæ¯")
                
                # ç›´æ¥ä½¿ç”¨æ¶ˆæ¯çš„åŸå§‹å†…å®¹ï¼Œä¸é‡æ–°æ•´ç†æ ¼å¼
                for message in chunk:
                    # æ·±æ‹·è´åŸå§‹æ¶ˆæ¯ï¼Œä¿æŒæ‰€æœ‰å­—æ®µ
                    result = message.to_dict()
                    
                    # åªæ·»åŠ å¿…è¦çš„ä¼šè¯ä¿¡æ¯
                    result['session_id'] = session_id
                    result['timestamp'] = time.time()
                    
                    # å¤„ç†å¤§å†…å®¹çš„ç‰¹æ®Šæƒ…å†µ
                    content = result.get('content', '')
                    show_content = result.get('show_content', '')
                    
                    # æ¸…ç†show_contentä¸­çš„base64å›¾ç‰‡æ•°æ®ï¼Œé¿å…JSONè¿‡å¤§ï¼Œä½†ä¿ç•™contentä¸­çš„base64
                    if isinstance(show_content, str) and 'data:image' in show_content:
                        try:
                            # å¦‚æœshow_contentæ˜¯JSONå­—ç¬¦ä¸²ï¼Œè§£æå¹¶æ¸…ç†
                            if show_content.strip().startswith('{'):
                                show_content_data = json.loads(show_content)
                                if isinstance(show_content_data, dict) and 'results' in show_content_data:
                                    if isinstance(show_content_data['results'], list):
                                        for item in show_content_data['results']:
                                            if isinstance(item, dict) and 'image' in item:
                                                if item['image'] and isinstance(item['image'], str) and item['image'].startswith('data:image'):
                                                    item['image'] = '[BASE64_IMAGE_REMOVED_FOR_DISPLAY]'
                                result['show_content'] = json.dumps(show_content_data, ensure_ascii=False)
                            else:
                                # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¸…ç†
                                import re
                                result['show_content'] = re.sub(r'data:image/[^;]+;base64,[A-Za-z0-9+/=]+', '[BASE64_IMAGE_REMOVED_FOR_DISPLAY]', show_content)
                        except (json.JSONDecodeError, Exception) as e:
                            logger.warning(f"æ¸…ç† show_content å¤±è´¥: {e}")
                            # å¦‚æœæ¸…ç†å¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤base64æ•°æ®
                            import re
                            result['show_content'] = re.sub(r'data:image/[^;]+;base64,[A-Za-z0-9+/=]+', '[BASE64_IMAGE_REMOVED_FOR_DISPLAY]', show_content)
                    
                    # ç‰¹æ®Šå¤„ç†å·¥å…·è°ƒç”¨ç»“æœï¼Œé¿å…JSONåµŒå¥—é—®é¢˜
                    if result.get('role') == 'tool' and isinstance(content, str):
                        try:
                            # å°è¯•è§£æcontentä¸­çš„JSONæ•°æ®
                            if content.strip().startswith('{'):
                                parsed_content = json.loads(content)
                                
                                # æ£€æŸ¥æ˜¯å¦æ˜¯åµŒå¥—çš„JSONç»“æ„
                                if isinstance(parsed_content, dict) and 'content' in parsed_content:
                                    inner_content = parsed_content['content']
                                    if isinstance(inner_content, str) and inner_content.strip().startswith('{'):
                                        try:
                                            # è§£æå†…å±‚JSONï¼Œè¿™é€šå¸¸æ˜¯å®é™…çš„å·¥å…·ç»“æœ
                                            tool_data = json.loads(inner_content)
                                            
                                            # æ¸…ç†å·¥å…·ç»“æœä¸­çš„å¤§æ•°æ®ï¼Œé¿å…JSONè¿‡å¤§
                                            if isinstance(tool_data, dict) and 'results' in tool_data:
                                                if isinstance(tool_data['results'], list):
                                                    for item in tool_data['results']:
                                                        if isinstance(item, dict):
                                                            # é™åˆ¶æ–‡æœ¬å­—æ®µé•¿åº¦ï¼Œä½†ä¿ç•™æ‰€æœ‰å­—æ®µ
                                                            for field in ['snippet', 'description', 'content']:
                                                                if field in item and isinstance(item[field], str):
                                                                    if len(item[field]) > 1000:
                                                                        item[field] = item[field][:1000] + '...[TRUNCATED]'
                                            
                                            # ç›´æ¥ä½¿ç”¨è§£æåçš„æ•°æ®
                                            result['content'] = tool_data
                                        except json.JSONDecodeError:
                                            # å†…å±‚è§£æå¤±è´¥ï¼Œä½¿ç”¨å¤–å±‚æ•°æ®
                                            result['content'] = parsed_content
                                    else:
                                        # å†…å±‚ä¸æ˜¯JSONå­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                                        result['content'] = parsed_content
                                else:
                                    # ä¸æ˜¯åµŒå¥—ç»“æ„ï¼Œç›´æ¥ä½¿ç”¨
                                    result['content'] = parsed_content
                                    
                        except json.JSONDecodeError as e:
                            logger.warning(f"è§£æå·¥å…·ç»“æœJSONå¤±è´¥: {e}")
                            # ä¿æŒåŸå§‹å­—ç¬¦ä¸²
                            pass
                    
                    # ç›´æ¥yieldåŸå§‹æ¶ˆæ¯ï¼Œä¸è¿›è¡Œå¤æ‚çš„åºåˆ—åŒ–å¤„ç†
                    yield result
                    await asyncio.sleep(0.01)  # é¿å…è¿‡å¿«å‘é€
                
                # åœ¨æ¯ä¸ªå—ä¹‹åè®©å‡ºæ§åˆ¶æƒï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                await asyncio.sleep(0)
            
            logger.info(f"ğŸ æµå¼å¤„ç†å®Œæˆï¼Œæ€»å…±å¤„ç†äº† {chunk_count} ä¸ªå—")
                
        except Exception as e:
            logger.error(f"âŒ æµå¼å¤„ç†å¼‚å¸¸: {e}")
            logger.error(f"ğŸ” å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            logger.error(f"ğŸ“‹ å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            error_result = {
                'type': 'error',
                'content': f"å¤„ç†å¤±è´¥: {str(e)}",
                'role': 'assistant',
                'message_id': str(uuid.uuid4()),
                'session_id': session_id,
                'show_content': f"å¤„ç†å¤±è´¥: {str(e)}"
            }
            yield error_result
    
    # ä¼šè¯ç®¡ç†æ–¹æ³•
    def interrupt_session(self, session_id: str, message: str = "ç”¨æˆ·è¯·æ±‚ä¸­æ–­") -> bool:
        """ä¸­æ–­æŒ‡å®šä¼šè¯"""
        return self.sage_controller.interrupt_session(session_id, message)
    
    def get_session_status(self, session_id: str):
        """è·å–ä¼šè¯çŠ¶æ€"""
        return self.sage_controller.get_session_status(session_id)
    
    def list_active_sessions(self):
        """åˆ—å‡ºæ‰€æœ‰æ´»è·ƒä¼šè¯"""
        return self.sage_controller.list_active_sessions()

# å…¨å±€å˜é‡
default_stream_service: Optional[SageStreamService] = None
all_active_sessions_service_map: Dict[str, Dict[str, Any]] = {}
tool_manager: Optional[ToolManager] = None
default_model_client: Optional[OpenAI] = None



async def initialize_tool_manager():
    """å¼‚æ­¥åˆå§‹åŒ–å·¥å…·ç®¡ç†å™¨"""
    # åˆ›å»ºå·¥å…·ç®¡ç†å™¨å®ä¾‹ï¼Œä½†ä¸è‡ªåŠ¨å‘ç°å·¥å…·
    manager = ToolManager(is_auto_discover=False)
    
    # æ‰‹åŠ¨è¿›è¡ŒåŸºç¡€å·¥å…·å‘ç°
    manager._auto_discover_tools()
    
    # è®¾ç½® MCP é…ç½®è·¯å¾„
    manager._mcp_setting_path = os.environ.get('SAGE_MCP_CONFIG_PATH', 'mcp_setting.json')
    
    # å¼‚æ­¥å‘ç° MCP å·¥å…·
    await manager._discover_mcp_tools(mcp_setting_path=manager._mcp_setting_path)
    
    return manager

async def initialize_system(server_args):
    """åˆå§‹åŒ–ç³»ç»Ÿ"""
    global default_stream_service, tool_manager, default_model_client
    
    logger.info("æ­£åœ¨åˆå§‹åŒ– Sage Stream Service...")
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯
        if server_args.default_llm_api_key:
            default_model_client = OpenAI(
                api_key=server_args.default_llm_api_key,
                base_url=server_args.default_llm_api_base_url
            )
            default_model_client.model = server_args.default_llm_model_name
            logger.info(f"é»˜è®¤æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {server_args.default_llm_model_name}")
        else:
            logger.warning("æœªé…ç½®é»˜è®¤ API å¯†é’¥ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        
        # åˆå§‹åŒ–å·¥å…·ç®¡ç†å™¨
        try:
            tool_manager = await initialize_tool_manager()
            logger.info("å·¥å…·ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"å·¥å…·ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            tool_manager = None
        
        # åˆå§‹åŒ–æµå¼æœåŠ¡
        if default_model_client:
            # ä»é…ç½®ä¸­æ„å»ºæ¨¡å‹é…ç½®å­—å…¸
            model_config_dict = {
                'model': server_args.default_llm_model_name,
                'max_tokens': server_args.default_llm_max_tokens,
                'temperature': server_args.default_llm_temperature
            }

            if server_args.preset_running_config:
                if os.path.exists(server_args.preset_running_config):
                    with open(server_args.preset_running_config, 'r') as f:
                        preset_running_config = json.load(f)
                else:
                    preset_running_config = {}
            else:
                preset_running_config = {}

            default_stream_service = SageStreamService(
                model=default_model_client,
                model_config=model_config_dict,
                tool_manager=tool_manager,
                preset_running_config=preset_running_config,
                workspace=server_args.workspace,
                memory_root=server_args.memory_root
            )
            logger.info("é»˜è®¤ SageStreamService åˆå§‹åŒ–æˆåŠŸ")
        else:
            logger.warning("æ¨¡å‹å®¢æˆ·ç«¯æœªé…ç½®ï¼Œæµå¼æœåŠ¡ä¸å¯ç”¨")
            
    except Exception as e:
        logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        logger.error(traceback.format_exc())

def add_cors_headers(response):
    """æ·»åŠ  CORS å¤´"""
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
    response.headers["Access-Control-Allow-Headers"] = "*"

async def cleanup_system():
    """æ¸…ç†ç³»ç»Ÿèµ„æº"""
    global default_stream_service, tool_manager, default_model_client
    
    logger.info("æ­£åœ¨æ¸…ç†ç³»ç»Ÿèµ„æº...")
    
    try:
        if tool_manager:
            # æ¸…ç†å·¥å…·ç®¡ç†å™¨èµ„æº
            logger.info("æ¸…ç†å·¥å…·ç®¡ç†å™¨èµ„æº")
            
        default_stream_service = None
        tool_manager = None
        default_model_client = None
        
        logger.info("ç³»ç»Ÿèµ„æºæ¸…ç†å®Œæˆ")
    except Exception as e:
        logger.error(f"ç³»ç»Ÿèµ„æºæ¸…ç†å¤±è´¥: {e}")

# Pydantic æ¨¡å‹å®šä¹‰
class ChatMessage(BaseModel):
    role: Optional[str] = None
    content: Optional[Any] = None
    message_id: Optional[str] = None
    type: Optional[str] = "normal"
    tool_calls: Optional[List[Dict[str, Any]]] = None
    tool_call_id: Optional[str] = None
    show_content: Optional[str] = None
    # æ·»åŠ å†å²å¯¹è¯ä¸­å¯èƒ½å­˜åœ¨çš„å­—æ®µ
    message_type: Optional[str] = None
    timestamp: Optional[float] = None
    chunk_id: Optional[str] = None
    is_final: Optional[bool] = None
    is_chunk: Optional[bool] = None
    metadata: Optional[Dict[str, Any]] = None
    session_id: Optional[str] = None

class StreamRequest(BaseModel):
    messages: List[ChatMessage]
    session_id: Optional[str] = None
    user_id: Optional[str] = None
    deep_thinking: Optional[Union[bool, str]] = None
    max_loop_count: int = 10
    multi_agent: Optional[Union[bool, str]] = None
    more_suggest: bool = False
    system_context: Optional[Dict[str, Any]] = None
    available_workflows: Optional[Dict[str, List[str]]] = None
    llm_model_config: Optional[Dict[str, Any]] = None
    system_prefix: Optional[str] = None
    available_tools: Optional[List[str]] = None

class ConfigRequest(BaseModel):
    api_key: str
    model_name: str = "deepseek-chat"
    base_url: str = "https://api.deepseek.com/v1"
    max_tokens: Optional[int] = 4096
    temperature: Optional[float] = 0.7

class ToolInfo(BaseModel):
    name: str
    description: str
    parameters: Dict[str, Any]
    type: str  # å·¥å…·ç±»å‹ï¼šbasic, mcp, agent
    source: str  # å·¥å…·æ¥æº

class SystemStatus(BaseModel):
    status: str
    service_name: str = "SageStreamService"
    tools_count: int
    active_sessions: int
    version: str = "1.0"

class InterruptRequest(BaseModel):
    message: str = "ç”¨æˆ·è¯·æ±‚ä¸­æ–­"


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "service": "ReagentStreamService"
    }

@app.get("/api/tools", response_model=List[ToolInfo])
async def get_tools(response: Response):
    """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
    add_cors_headers(response)
    
    try:
        tools = []
        
        if tool_manager:
            available_tools = tool_manager.list_tools_with_type()
            
            for tool_info in available_tools:
                tools.append(ToolInfo(
                    name=tool_info.get("name", ""),
                    description=tool_info.get("description", ""),
                    parameters=tool_info.get("parameters", {}),
                    type=tool_info.get("type", "basic"),
                    source=tool_info.get("source", "internal")
                ))
        
        return tools
    except Exception as e:
        logger.error(f"è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {str(e)}")

@app.post("/api/stream")
async def stream_chat(request: StreamRequest):
    """æµå¼èŠå¤©æ¥å£"""
    if not default_stream_service:
        raise HTTPException(status_code=503, detail="æœåŠ¡æœªé…ç½®æˆ–ä¸å¯ç”¨")
    
    logger.info(f"Server: è¯·æ±‚å‚æ•°: {request}")
    # ç”Ÿæˆä¼šè¯ID
    # llm_model_config={'model': '', 'maxTokens': '', 'temperature': ''}
    # å¦‚æœæ˜¯value æ˜¯ç©ºï¼Œåˆ é™¤key
    if request.llm_model_config:
        request.llm_model_config = {k: v for k, v in request.llm_model_config.items() if v is not None and v != ''}

    session_id = request.session_id or str(uuid.uuid4())
    # åˆ¤æ–­æ˜¯å¦è¦åˆå§‹åŒ–æ–°çš„ sage service è¿˜æ˜¯ä½¿ç”¨é»˜è®¤çš„
    # å–å†³äºæ˜¯å¦éœ€è¦è‡ªå®šä¹‰æ¨¡å‹ä»¥åŠ agent çš„system prefix ï¼Œä»¥åŠå¯¹tool çš„å·¥å…·æ˜¯å¦æœ‰é™åˆ¶
    if request.llm_model_config or request.system_prefix or request.available_tools:
        # æ ¹æ®model config åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯
        model_client = OpenAI(
            api_key=request.llm_model_config.get('api_key', server_args.default_llm_api_key),
            base_url=request.llm_model_config.get('base_url', server_args.default_llm_api_base_url),
        )
        llm_model_config = {
            'model': request.llm_model_config.get('model', server_args.default_llm_model_name),
            'max_tokens': int(request.llm_model_config.get('max_tokens', server_args.default_llm_max_tokens)),
            'temperature': float(request.llm_model_config.get('temperature', server_args.default_llm_temperature))
        }
        logger.info(f"åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®: {llm_model_config}")

        if request.available_tools:
            logger.info(f"åˆå§‹åŒ–å·¥å…·ä»£ç†ï¼Œå¯ç”¨å·¥å…·: {request.available_tools}")
            start_tool_proxy = time.time()
            # å¦‚æœrequest.multi_agent æ˜¯trueï¼Œè¦ç¡®ä¿request.available_toolsæ²¡æœ‰ complete_task è¿™ä¸ªå·¥å…·
            if request.multi_agent and 'complete_task' in request.available_tools:
                request.available_tools.remove('complete_task')
            tool_proxy = ToolProxy(tool_manager,request.available_tools)
            end_tool_proxy = time.time()
            logger.info(f"åˆå§‹åŒ–å·¥å…·ä»£ç†è€—æ—¶: {end_tool_proxy - start_tool_proxy} ç§’")
        else:
            tool_proxy = tool_manager

        start_stream_service = time.time()
        # åˆå§‹åŒ–æ–°çš„ sage service
        stream_service = SageStreamService(
            model=model_client,
            model_config=llm_model_config,
            tool_manager=tool_proxy,
            preset_running_config={
                "system_prefix": request.system_prefix
            },
            workspace=server_args.workspace,
            memory_root=server_args.memory_root
        )
        end_stream_service = time.time()
        logger.info(f"åˆå§‹åŒ–æµå¼æœåŠ¡è€—æ—¶: {end_stream_service - start_stream_service} ç§’")
        all_active_sessions_service_map[session_id] = {
            'stream_service': stream_service,
            'session_id': session_id,
            "is_default": False
        }
    else:
        logger.info(f"ä½¿ç”¨é»˜è®¤çš„æµå¼æœåŠ¡ï¼Œä¼šè¯ID: {session_id}")
        # ä½¿ç”¨é»˜è®¤çš„ sage service
        stream_service = default_stream_service
        # è®°å½•ä¼šè¯ID
        all_active_sessions_service_map[session_id] = {
            'stream_service': stream_service,
            'session_id': session_id,
            "is_default": True
        }

    async def generate_stream():
        """ç”ŸæˆSSEæµ"""
        try:
            # ç›´æ¥è½¬æ¢æ¶ˆæ¯æ ¼å¼ï¼Œä¸è¿›è¡Œå†…å®¹è°ƒæ•´
            messages = []
            for msg in request.messages:
                # ä¿æŒåŸå§‹æ¶ˆæ¯çš„æ‰€æœ‰å­—æ®µ
                message_dict = msg.model_dump()
                # å¦‚æœæœ‰content ä¸€å®šè¦è½¬åŒ–æˆstr
                if message_dict.get('content'):
                    message_dict['content'] = str(message_dict['content'])
                messages.append(message_dict)
            
            logger.info(f"å¼€å§‹æµå¼å¤„ç†ï¼Œä¼šè¯ID: {session_id}")
            
            # æ‰“å°è¯·æ±‚ä½“å†…å®¹
            logger.info(f"è¯·æ±‚ä½“å†…å®¹: {request}")
            # å¤„ç†æµå¼å“åº”ï¼Œä¼ é€’æ‰€æœ‰å‚æ•°
            async for result in stream_service.process_stream(
                messages=messages, 
                session_id=session_id,
                user_id=request.user_id,
                deep_thinking=request.deep_thinking,
                max_loop_count=request.max_loop_count,
                multi_agent=request.multi_agent,
                more_suggest=request.more_suggest,
                system_context=request.system_context,
                available_workflows=request.available_workflows
            ):
                # å¤„ç†å¤§JSONçš„åˆ†å—ä¼ è¾“
                try:
                    json_str = json.dumps(result, ensure_ascii=False)
                    json_size = len(json_str)
                    
                    # å¯¹äºè¶…å¤§JSONï¼Œä½¿ç”¨åˆ†å—å‘é€ç¡®ä¿å®Œæ•´æ€§
                    if json_size > 32768:  # 32KBä»¥ä¸Šä½¿ç”¨åˆ†å—å‘é€
                        logger.info(f"ğŸ”„ å¤§JSONåˆ†å—å‘é€: {json_size} å­—ç¬¦")
                        
                        # åˆ†å—å‘é€å¤§JSON
                        chunk_size = 8192  # 8KB per chunk
                        total_chunks = (json_size + chunk_size - 1) // chunk_size
                        
                        # å‘é€åˆ†å—å¼€å§‹æ ‡è®°
                        start_marker = {
                            'type': 'chunk_start',
                            'message_id': result.get('message_id', 'unknown'),
                            'total_size': json_size,
                            'total_chunks': total_chunks,
                            'chunk_size': chunk_size,
                            'original_type': result.get('type', 'unknown')
                        }
                        yield json.dumps(start_marker, ensure_ascii=False) + "\n"
                        await asyncio.sleep(0.01)  # å»¶è¿Ÿç¡®ä¿å‰ç«¯å‡†å¤‡å¥½
                        
                        for i in range(total_chunks):
                            start = i * chunk_size
                            end = min(start + chunk_size, json_size)
                            chunk_data = json_str[start:end]
                            
                            # åˆ›å»ºåˆ†å—æ¶ˆæ¯
                            chunk_message = {
                                'type': 'json_chunk',
                                'message_id': result.get('message_id', 'unknown'),  # æ·»åŠ message_idå­—æ®µ
                                'chunk_id': f"{result.get('message_id', 'unknown')}_{i}",
                                'chunk_index': i,
                                'total_chunks': total_chunks,
                                'chunk_data': chunk_data,
                                'chunk_size': len(chunk_data),
                                'is_final': i == total_chunks - 1,
                                'checksum': hash(chunk_data) % 1000000
                            }
                            
                            yield json.dumps(chunk_message, ensure_ascii=False) + "\n"
                            await asyncio.sleep(0.005)  # é€‚ä¸­å»¶è¿Ÿç¡®ä¿é¡ºåº
                        
                        # å‘é€åˆ†å—ç»“æŸæ ‡è®°
                        end_marker = {
                            'type': 'chunk_end',
                            'message_id': result.get('message_id', 'unknown'),
                            'total_chunks': total_chunks,
                            'expected_size': json_size,
                            'original_type': result.get('type', 'unknown')
                        }
                        yield json.dumps(end_marker, ensure_ascii=False) + "\n"
                        
                        logger.info(f"âœ… å®Œæˆåˆ†å—å‘é€: {total_chunks} å—")
                    else:
                        # å°JSONç›´æ¥å‘é€
                        yield json.dumps(result, ensure_ascii=False) + "\n"
                        
                except Exception as e:
                    logger.error(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}")
                    # åˆ›å»ºé”™è¯¯å“åº”
                    error_data = {
                        'type': 'error',
                        'message_id': result.get('message_id', 'error'),
                        'content': f'æ•°æ®å¤„ç†é”™è¯¯: {str(e)}',
                        'original_size': len(str(result)),
                        'error': True
                    }
                    yield json.dumps(error_data, ensure_ascii=False) + "\n"
                    
                await asyncio.sleep(0.01)  # é¿å…è¿‡å¿«å‘é€
                
            # å‘é€æµç»“æŸæ ‡è®°
            end_data = {
                'type': 'stream_end',
                'session_id': session_id,
                'timestamp': time.time()
            }
            yield json.dumps(end_data, ensure_ascii=False) + "\n"
            
        except Exception as e:
            logger.error(f"æµå¼å¤„ç†å¼‚å¸¸: {e}")
            logger.error(traceback.format_exc())
            error_data = {
                'type': 'error',
                'message': str(e),
                'session_id': session_id
            }
            yield json.dumps(error_data, ensure_ascii=False) + "\n"
        finally:
            # æ¸…ç†ä¼šè¯èµ„æº
            if session_id in all_active_sessions_service_map:
                del all_active_sessions_service_map[session_id]
                logger.info(f"ä¼šè¯ {session_id} èµ„æºå·²æ¸…ç†")
    return StreamingResponse(
        generate_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
            "Access-Control-Allow-Headers": "*",
        }
    )

@app.post("/api/sessions/{session_id}/interrupt")
async def interrupt_session(session_id: str, request: InterruptRequest = None):
    """ä¸­æ–­æŒ‡å®šä¼šè¯"""
    session_info = all_active_sessions_service_map.get(session_id)
    if not session_info:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    stream_service = session_info['stream_service']

    if not stream_service:
        raise HTTPException(status_code=503, detail="æœåŠ¡æœªé…ç½®æˆ–ä¸å¯ç”¨")
    try:
        message = request.message if request else "ç”¨æˆ·è¯·æ±‚ä¸­æ–­"
        success = stream_service.interrupt_session(session_id, message)
        
        if success:
            logger.info(f"ä¼šè¯ {session_id} ä¸­æ–­æˆåŠŸ")
            return {
                "status": "success",
                "message": f"ä¼šè¯ {session_id} å·²ä¸­æ–­",
                "session_id": session_id
            }
        else:
            return {
                "status": "not_found",
                "message": f"ä¼šè¯ {session_id} ä¸å­˜åœ¨æˆ–å·²ç»“æŸ",
                "session_id": session_id
            }
    except Exception as e:
        logger.error(f"ä¸­æ–­ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¸­æ–­ä¼šè¯å¤±è´¥: {str(e)}")

# è·å–æŒ‡å®šseesion id çš„å½“å‰çš„ä»»åŠ¡ç®¡ç†å™¨ä¸­çš„ä»»åŠ¡çŠ¶æ€ä¿¡æ¯ 
@app.post("/api/sessions/{session_id}/tasks_status")
async def get_session_status(session_id: str):
    """è·å–æŒ‡å®šä¼šè¯çš„çŠ¶æ€"""
    session_info = all_active_sessions_service_map.get(session_id)
    if not session_info:
        return {
            "status": "not_found",
            "message": f"ä¼šè¯ {session_id} å·²å®Œæˆæˆ–è€…ä¸å­˜åœ¨",
            "session_id": session_id,
            "tasks_status": None
        }
    stream_service = session_info['stream_service']
    tasks_status = stream_service.sage_controller.get_tasks_status(session_id)
    tasks_status['tasks']
    logger.info(f"è·å–ä¼šè¯ {session_id} ä»»åŠ¡æ•°é‡ï¼š{len(tasks_status['tasks'])}")
    return {
        "status": "success",
        "message": f"ä¼šè¯ {session_id} çŠ¶æ€è·å–æˆåŠŸ",
        "session_id": session_id,
        "tasks_status": tasks_status
    }


@app.post("/api/sessions/{session_id}/file_workspace")
async def get_file_workspace(session_id: str):
    session_info = all_active_sessions_service_map.get(session_id)
    if not session_info:
        return {
            "status": "success",
            "message": f"ä¼šè¯ {session_id} å·²å®Œæˆæˆ–è€…ä¸å­˜åœ¨",
            "session_id": session_id,
            "files": []
        }
    try:
        session_context = get_session_context(session_id)
    except Exception as e:
        return {
            "status": "success",
            "message": f"ä¼šè¯ {session_id} å·²å®Œæˆæˆ–è€…ä¸å­˜åœ¨",
            "session_id": session_id,
            "files": []
        }
    # è¿™ä¸ªä¼šè¯çš„å·¥ä½œç©ºé—´çš„ï¼Œç»å¯¹è·¯å¾„
    workspace_path = session_context.agent_workspace
    
    if not os.path.exists(workspace_path):
        return {
            "status": "success",
            "message": "å·¥ä½œç©ºé—´ä¸ºç©º",
            "session_id": session_id,
            "files": []
        }
    
    files = []
    try:
        for root, dirs, filenames in os.walk(workspace_path):
            for filename in filenames:
                file_path = os.path.join(root, filename)
                # è®¡ç®—ç›¸å¯¹äºå·¥ä½œç©ºé—´çš„è·¯å¾„
                relative_path = os.path.relpath(file_path, workspace_path)
                file_stat = os.stat(file_path)
                files.append({
                    "name": filename,
                    "path": relative_path,
                    "size": file_stat.st_size,
                    "modified_time": file_stat.st_mtime,
                    "is_directory": False
                })
            
            for dirname in dirs:
                dir_path = os.path.join(root, dirname)
                relative_path = os.path.relpath(dir_path, workspace_path)
                files.append({
                    "name": dirname,
                    "path": relative_path,
                    "size": 0,
                    "modified_time": os.stat(dir_path).st_mtime,
                    "is_directory": True
                })
        logger.info(f"è·å–ä¼šè¯ {session_id} å·¥ä½œç©ºé—´æ–‡ä»¶æ•°é‡ï¼š{len(files)}")
        return {
            "status": "success",
            "message": "è·å–æ–‡ä»¶åˆ—è¡¨æˆåŠŸ",
            "session_id": session_id,
            "files": files,
            "agent_workspace": session_context.agent_workspace
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}",
            "session_id": session_id,
            "files": []
        }

# æŒ‡å®šagent workspace ä»¥åŠfile è¿›è¡Œä¸‹è½½
@app.get("/api/sessions/file_workspace/download")
async def download_file(request: Request):
    """ä¸‹è½½å·¥ä½œç©ºé—´ä¸­çš„æŒ‡å®šæ–‡ä»¶"""
    file_path = request.query_params.get("file_path")
    workspace_path = request.query_params.get("workspace_path")
    
    # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
    full_file_path = os.path.join(workspace_path, file_path)
    
    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶è·¯å¾„åœ¨å·¥ä½œç©ºé—´å†…
    if not os.path.abspath(full_file_path).startswith(os.path.abspath(workspace_path)):
        raise HTTPException(status_code=403, detail="è®¿é—®è¢«æ‹’ç»ï¼šæ–‡ä»¶è·¯å¾„è¶…å‡ºå·¥ä½œç©ºé—´èŒƒå›´")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(full_file_path):
        raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ï¼ˆä¸æ˜¯ç›®å½•ï¼‰
    if not os.path.isfile(full_file_path):
        raise HTTPException(status_code=400, detail=f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {file_path}")
    
    try:
        # è¿”å›æ–‡ä»¶å†…å®¹
        return FileResponse(
            path=full_file_path,
            filename=os.path.basename(file_path),
            media_type='application/octet-stream'
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}")

class ExecToolRequest(BaseModel):
    tool_name: str
    tool_params: Dict[str, Any]

@app.post("/api/tools/exec")
async def exec_tool(request: ExecToolRequest):
    """æ‰§è¡Œå·¥å…·"""
    logger.info(f"æ‰§è¡Œå·¥å…·è¯·æ±‚: {request}")
    try:
        # æ£€æµ‹å·¥å…·æ˜¯å¦å­˜åœ¨
        if request.tool_name not in tool_manager.tools.keys():
            logger.error(f"æ‰§è¡Œå·¥å…·å¤±è´¥: {request.tool_name}")
            return {"status": "error", "message": "å·¥å…·ä¸å­˜åœ¨"}

        tool_response = tool_manager.run_tool(
                tool_name=request.tool_name,
                session_context=None,
                session_id="",
                **request.tool_params
            )
        if tool_response:
            logger.info(f"æ‰§è¡Œå·¥å…·æˆåŠŸ: {request.tool_name}")
            return {"status": "success", "message": "å·¥å…·æ‰§è¡ŒæˆåŠŸ", "data": tool_response}
        else:
            logger.error(f"æ‰§è¡Œå·¥å…·å¤±è´¥: {request.tool_name}")
            return {"status": "error", "message": "å·¥å…·æ‰§è¡Œå¤±è´¥"}
    except Exception as e:
        logger.error(f"æ‰§è¡Œå·¥å…·å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå·¥å…·å¤±è´¥: {str(e)}")


class MCPServerRequest(BaseModel):
    name: str
    streaming_http_url: Optional[str] = None
    sse_url: Optional[str] = None
    api_key: Optional[str] = None
    disabled: bool = False

@app.post("/api/mcp/add")
async def add_mcp_server(request: MCPServerRequest, response: Response):
    """æ·»åŠ MCP serveråˆ°tool manager"""
    add_cors_headers(response)
    
    try:
        global tool_manager, default_stream_service
        
        if not tool_manager:
            raise HTTPException(status_code=503, detail="å·¥å…·ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        logger.info(f"å¼€å§‹æ·»åŠ MCP server: {request.name}")
        
        
        # æ·»åŠ æ–°çš„MCP serveråˆ°å·¥å…·ç®¡ç†å™¨
        success = tool_manager.register_mcp_server(request.name, server_config)
        if success:
            # è¯»å–ç°æœ‰çš„MCPé…ç½®
            mcp_config_path = server_args.mcp_config
            if os.path.exists(mcp_config_path):
                with open(mcp_config_path, 'r', encoding='utf-8') as f:
                    mcp_config = json.load(f)
            else:
                mcp_config = {"mcpServers": {}}
            
            # æ·»åŠ æ–°çš„MCP serveré…ç½®
            server_config = {
                "disabled": request.disabled
            }
            if request.streaming_http_url:
                server_config["streaming_http_url"] = request.streaming_http_url
            if request.sse_url:
                server_config["sse_url"] = request.sse_url
            if request.api_key:
                server_config["api_key"] = request.api_key
            
            mcp_config["mcpServers"][request.name] = server_config
            
            # ä¿å­˜æ›´æ–°åçš„é…ç½®
            with open(mcp_config_path, 'w', encoding='utf-8') as f:
                json.dump(mcp_config, f, indent=4, ensure_ascii=False)

            # ä¹‹åè¦é€šè¿‡è¿™ä¸ªæ¥å£è·å–åˆ°æ³¨å†Œæƒ…å†µçš„è¯¦ç»†ä¿¡æ¯ï¼Œé‚£äº›tool æ³¨å†ŒæˆåŠŸäº†ï¼Œé‚£äº›toolæ²¡æœ‰æˆåŠŸã€‚        
        
            return {
                "status": "success",
                "message": f"MCP server {request.name} æ·»åŠ æˆåŠŸ",
                "server_name": request.name,
                "timestamp": time.time()
            }
        else:
            return {
                "status": "error",
                "message": f"MCP server {request.name} æ·»åŠ å¤±è´¥",
                "server_name": request.name,
                "timestamp": time.time()
            }
        
    except Exception as e:
        logger.error(f"æ·»åŠ MCP serverå¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"æ·»åŠ MCP serverå¤±è´¥: {str(e)}")



# ä¸»å‡½æ•°
if __name__ == "__main__":
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs(server_args.logs_dir, exist_ok=True)
    os.makedirs(server_args.workspace, exist_ok=True)
    
    # å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼
    if server_args.daemon:
        import daemon
        import daemon.pidfile
        
        context = daemon.DaemonContext(
            working_directory=os.getcwd(),
            umask=0o002,
            pidfile=daemon.pidfile.TimeoutPIDLockFile(server_args.pid_file),
        )
        
        with context:
            uvicorn.run(
                app,
                host=server_args.host,
                port=server_args.port,
                log_level="debug",
                reload=False
            )
    else:
        uvicorn.run(
            app,
            host=server_args.host,
            port=server_args.port,
            log_level="debug",
            reload=False
        )