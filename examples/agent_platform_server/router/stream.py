"""
æµå¼èŠå¤©æ¥å£è·¯ç”±æ¨¡å—
"""
import json
import uuid
import asyncio
import traceback
import time
from typing import Dict, Any, Optional, List, Union
from fastapi import APIRouter
from entities.entities import SageHTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

from sagents.utils.logger import logger
import globals.variables as global_vars

# åˆ›å»ºè·¯ç”±å™¨
stream_router = APIRouter()

class Message(BaseModel):
    role: str
    content: Union[str, List[Dict[str, Any]]]

class StreamRequest(BaseModel):
    messages: List[Message]
    session_id: Optional[str] = None
    user_id: Optional[str] = None
    deep_thinking: Optional[bool] = None
    max_loop_count: Optional[int] = None
    multi_agent: Optional[bool] = None
    more_suggest: Optional[bool] = None
    system_context: Optional[Dict[str, Any]] = None
    available_workflows: Optional[Dict[str, List[str]]] = None
    llm_model_config: Optional[Dict[str, Any]] = None
    system_prefix: Optional[str] = None
    available_tools: Optional[List[str]] = None
    force_summary: Optional[bool] = False
    agent_id: Optional[str] = None
    agent_name: Optional[str] = None

    def __init__(self, **data):
        super().__init__(**data)
        # ç¡®ä¿ messages ä¸­çš„æ¯ä¸ªæ¶ˆæ¯éƒ½æœ‰ role å’Œ content
        if self.messages:
            for i, msg in enumerate(self.messages):
                if isinstance(msg, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸º Message å¯¹è±¡
                    self.messages[i] = Message(**msg)
                elif not hasattr(msg, 'role') or not hasattr(msg, 'content'):
                    raise ValueError(f"æ¶ˆæ¯ {i} ç¼ºå°‘å¿…è¦çš„ 'role' æˆ– 'content' å­—æ®µ")



def _clean_llm_model_config(llm_model_config: dict) -> dict:
    """æ¸…ç†LLMæ¨¡å‹é…ç½®ï¼Œç§»é™¤ç©ºå€¼"""
    if not llm_model_config:
        return {}
    return {k: v for k, v in llm_model_config.items() if v is not None and v != ''}


def _build_llm_model_config(request_config: dict, server_args) -> dict:
    """æ„å»ºLLMæ¨¡å‹é…ç½®"""
    llm_model_config = {
        'model': request_config.get('model', server_args.default_llm_model_name)
    }
    
    # åªæœ‰åœ¨æœ‰æœ‰æ•ˆçš„max_tokenså€¼æ—¶æ‰æ·»åŠ è¯¥é”®ï¼Œé¿å…Noneå€¼å¯¼è‡´é”™è¯¯
    max_tokens_value = request_config.get('max_tokens', server_args.default_llm_max_tokens)
    if max_tokens_value is not None:
        llm_model_config['max_tokens'] = int(max_tokens_value)
        
    # åªæœ‰åœ¨æœ‰æœ‰æ•ˆçš„temperatureå€¼æ—¶æ‰æ·»åŠ è¯¥é”®ï¼Œé¿å…Noneå€¼å¯¼è‡´é”™è¯¯
    temperature_value = request_config.get('temperature', server_args.default_llm_temperature)
    if temperature_value is not None:
        llm_model_config['temperature'] = float(temperature_value)
    
    return llm_model_config


def _create_model_client(request_config: dict, server_args):
    """åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯"""
    from openai import OpenAI
    
    api_key = request_config.get('api_key', server_args.default_llm_api_key)
    base_url = request_config.get('base_url', server_args.default_llm_api_base_url)
    
    logger.info(f"åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®api_key: {api_key}")
    logger.info(f"åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®base_url: {base_url}")
    logger.info(f"åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®model: {request_config.get('model', server_args.default_llm_model_name)}")
    
    return OpenAI(api_key=api_key, base_url=base_url)


def _create_tool_proxy(request, global_vars):
    """åˆ›å»ºå·¥å…·ä»£ç†"""
    if not request.available_tools:
        return global_vars.get_tool_manager()
    
    logger.info(f"åˆå§‹åŒ–å·¥å…·ä»£ç†ï¼Œå¯ç”¨å·¥å…·: {request.available_tools}")
    
    # å¦‚æœrequest.multi_agent æ˜¯trueï¼Œè¦ç¡®ä¿request.available_toolsæ²¡æœ‰ complete_task è¿™ä¸ªå·¥å…·
    if request.multi_agent and 'complete_task' in request.available_tools:
        request.available_tools.remove('complete_task')
    
    from sagents.tool.tool_proxy import ToolProxy
    tool_proxy = ToolProxy(global_vars.get_tool_manager(), request.available_tools)
        
    return tool_proxy


def _create_stream_service(model_client, llm_model_config, tool_proxy, request, server_args, max_model_len):
    """åˆ›å»ºæµå¼æœåŠ¡"""    
    from handler import SageStreamService
    stream_service = SageStreamService(
        model=model_client,
        model_config=llm_model_config,
        tool_manager=tool_proxy,
        preset_running_config={
            "system_prefix": request.system_prefix
        },
        workspace=server_args.workspace,
        memory_root=server_args.memory_root,
        max_model_len=max_model_len
    )
    return stream_service


def _setup_stream_service(request: StreamRequest):
    """è®¾ç½®æµå¼æœåŠ¡ï¼Œè¿”å›(stream_service, session_id)"""
    session_id = request.session_id or str(uuid.uuid4())
    
    # åˆ¤æ–­æ˜¯å¦è¦åˆå§‹åŒ–æ–°çš„ sage service è¿˜æ˜¯ä½¿ç”¨é»˜è®¤çš„
    if request.llm_model_config or request.system_prefix or request.available_tools:
        # æ ¹æ®model config åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯
        server_args = global_vars.get_server_args()
        
        model_client = _create_model_client(request.llm_model_config, server_args)
        llm_model_config = _build_llm_model_config(request.llm_model_config, server_args)
        max_model_len = request.llm_model_config.get('max_model_len', server_args.default_llm_max_model_len)
        
        logger.info(f"åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®: {llm_model_config}")
        
        tool_proxy = _create_tool_proxy(request, global_vars)
        stream_service = _create_stream_service(model_client, llm_model_config, tool_proxy, request, server_args, max_model_len)
        
        all_active_sessions_service_map = global_vars.get_all_active_sessions_service_map()
        all_active_sessions_service_map[session_id] = {
            'stream_service': stream_service,
            'session_id': session_id,
            "is_default": False
        }
    else:
        logger.info(f"ä½¿ç”¨é»˜è®¤çš„æµå¼æœåŠ¡ï¼Œä¼šè¯ID: {session_id}")
        # ä½¿ç”¨é»˜è®¤çš„ sage service
        stream_service = global_vars.get_default_stream_service()
        # è®°å½•ä¼šè¯ID
        all_active_sessions_service_map = global_vars.get_all_active_sessions_service_map()
        all_active_sessions_service_map[session_id] = {
            'stream_service': stream_service,
            'session_id': session_id,
            "is_default": True
        }
    
    return stream_service, session_id


def _prepare_messages(request_messages):
    """å‡†å¤‡å’Œæ ¼å¼åŒ–æ¶ˆæ¯"""
    messages = []
    for msg in request_messages:
        # ä¿æŒåŸå§‹æ¶ˆæ¯çš„æ‰€æœ‰å­—æ®µ
        message_dict = msg.model_dump()
        # å…ˆåˆ¤æ–­åŸæ¶ˆæ¯æ˜¯å¦å­˜åœ¨message_idå­—æ®µï¼Œ ä¸å­˜åœ¨åˆ™åˆå§‹åŒ–ä¸€ä¸ª
        if 'message_id' not in message_dict or not message_dict['message_id']:
            message_dict['message_id'] = str(uuid.uuid4())  # ä¸ºæ¯ä¸ªæ¶ˆæ¯ç”Ÿæˆå”¯ä¸€ID
        # å¦‚æœæœ‰content ä¸€å®šè¦è½¬åŒ–æˆstr
        if message_dict.get('content'):
            message_dict['content'] = str(message_dict['content'])
        messages.append(message_dict)
    return messages


def _initialize_message_collector(messages):
    """åˆå§‹åŒ–æ¶ˆæ¯æ”¶é›†å™¨"""
    message_collector = {}  # {message_id: merged_message}
    message_order = []  # ä¿æŒæ¶ˆæ¯çš„åŸå§‹é¡ºåº
    
    # å°†è¯·æ±‚çš„messagesæ·»åŠ åˆ°åˆå§‹åŒ–ä¸­
    for msg in messages:
        msg_id = msg['message_id']
        message_collector[msg_id] = msg
        message_order.append(msg_id)
    
    return message_collector, message_order


def _update_message_collector(message_collector, message_order, result):
    """æ›´æ–°æ¶ˆæ¯æ”¶é›†å™¨"""
    if not isinstance(result, dict) or not result.get('message_id'):
        return
    
    message_id = result['message_id']
    # å¦‚æœæ˜¯æ–°æ¶ˆæ¯ï¼Œåˆå§‹åŒ–
    if message_id not in message_collector:
        message_collector[message_id] = result
        message_order.append(message_id)
    else:
        # å¯¹äºå·¥å…·è°ƒç”¨ç»“æœæ¶ˆæ¯ï¼Œå®Œæ•´æ›¿æ¢è€Œä¸æ˜¯åˆå¹¶
        if result.get('role') != 'tool':
            # åˆå¹¶contentå’Œshow_contentå­—æ®µï¼ˆè¿½åŠ ï¼‰
            if result.get('content'):
                message_collector[message_id]['content'] += str(result['content'])
            if result.get('show_content'):
                message_collector[message_id]['show_content'] += str(result['show_content'])


async def _send_chunked_json(result):
    """å‘é€åˆ†å—JSONæ•°æ®"""
    json_str = json.dumps(result, ensure_ascii=False)
    json_size = len(json_str)
    
    # å¯¹äºè¶…å¤§JSONï¼Œä½¿ç”¨åˆ†å—å‘é€ç¡®ä¿å®Œæ•´æ€§
    if json_size > 32768:  # 32KBä»¥ä¸Šä½¿ç”¨åˆ†å—å‘é€
        logger.info(f"ğŸ”„ å¤§JSONåˆ†å—å‘é€: {json_size} å­—ç¬¦")
        
        # åˆ†å—å‘é€å¤§JSON
        chunk_size = 8192  # 8KB per chunk
        total_chunks = (json_size + chunk_size - 1) // chunk_size
        
        # å‘é€åˆ†å—å¼€å§‹æ ‡è®°
        start_marker = {
            'type': 'chunk_start',
            'message_id': result.get('message_id', 'unknown'),
            'total_size': json_size,
            'total_chunks': total_chunks,
            'chunk_size': chunk_size,
            'original_type': result.get('type', 'unknown')
        }
        yield json.dumps(start_marker, ensure_ascii=False) + "\n"
        await asyncio.sleep(0.01)  # å»¶è¿Ÿç¡®ä¿å‰ç«¯å‡†å¤‡å¥½
        
        for i in range(total_chunks):
            start = i * chunk_size
            end = min(start + chunk_size, json_size)
            chunk_data = json_str[start:end]
            
            # åˆ›å»ºåˆ†å—æ¶ˆæ¯
            chunk_message = {
                'type': 'json_chunk',
                'message_id': result.get('message_id', 'unknown'),  # æ·»åŠ message_idå­—æ®µ
                'chunk_id': f"{result.get('message_id', 'unknown')}_{i}",
                'chunk_index': i,
                'total_chunks': total_chunks,
                'chunk_data': chunk_data,
                'chunk_size': len(chunk_data),
                'is_final': i == total_chunks - 1,
                'checksum': hash(chunk_data) % 1000000
            }
            
            yield json.dumps(chunk_message, ensure_ascii=False) + "\n"
            await asyncio.sleep(0.005)  # é€‚ä¸­å»¶è¿Ÿç¡®ä¿é¡ºåº
        
        # å‘é€åˆ†å—ç»“æŸæ ‡è®°
        end_marker = {
            'type': 'chunk_end',
            'message_id': result.get('message_id', 'unknown'),
            'total_chunks': total_chunks,
            'expected_size': json_size,
            'original_type': result.get('type', 'unknown')
        }
        yield json.dumps(end_marker, ensure_ascii=False) + "\n"
        
        logger.info(f"âœ… å®Œæˆåˆ†å—å‘é€: {total_chunks} å—")
    else:
        # å°JSONç›´æ¥å‘é€
        yield json.dumps(result, ensure_ascii=False) + "\n"


async def _create_conversation_title(request):
    """åˆ›å»ºä¼šè¯æ ‡é¢˜"""
    if not request.messages or len(request.messages) == 0:
        return "æ–°ä¼šè¯"
    
    # ä½¿ç”¨ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
    first_message = request.messages[0].content
    if isinstance(first_message, str):
        conversation_title = first_message[:50] + "..." if len(first_message) > 50 else first_message
    elif isinstance(first_message, list) and len(first_message) > 0:
        # å¦‚æœæ˜¯å¤šæ¨¡æ€æ¶ˆæ¯ï¼Œå°è¯•æå–æ–‡æœ¬å†…å®¹
        for item in first_message:
            if isinstance(item, dict) and item.get('type') == 'text':
                text_content = item.get('text', '')
                conversation_title = text_content[:50] + "..." if len(text_content) > 50 else text_content
                break
        else:
            conversation_title = "å¤šæ¨¡æ€æ¶ˆæ¯"
    else:
        conversation_title = "æ–°ä¼šè¯"
    
    return conversation_title


async def _save_conversation_if_needed(db_manager, session_id, request):
    """å¦‚æœéœ€è¦ï¼Œä¿å­˜æ–°ä¼šè¯"""
    existing_conversation = await db_manager.get_conversation(session_id)
    if not existing_conversation:
        conversation_title = await _create_conversation_title(request)
        await db_manager.save_conversation(
            user_id=request.user_id or "default_user",
            agent_id=request.agent_id or "default_agent",
            agent_name=request.agent_name or "Sage Assistant",
            messages=[],
            session_id=session_id,
            title=conversation_title
        )
        logger.info(f"åˆ›å»ºæ–°ä¼šè¯: {session_id}, æ ‡é¢˜: {conversation_title}")


async def _save_messages_to_db(db_manager, session_id, message_collector, message_order):
    """ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“"""
    try:
        # æŒ‰ç…§åŸå§‹é¡ºåºå°†åˆå¹¶çš„æ¶ˆæ¯æ·»åŠ åˆ°ç°æœ‰conversation
        for message_id in message_order:
            if message_id in message_collector:
                merged_message = message_collector[message_id]
                # æ·»åŠ æ¶ˆæ¯åˆ°conversation
                await db_manager.add_message_to_conversation(session_id, merged_message)
        logger.info(f"æˆåŠŸæŒ‰é¡ºåºä¿å­˜ {len(message_collector)} æ¡æ¶ˆæ¯åˆ°ç°æœ‰conversation {session_id}")
    except Exception as e:
        logger.error(f"ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")


@stream_router.post("/api/stream")
async def stream_chat(request: StreamRequest):
    """æµå¼èŠå¤©æ¥å£"""
    if not global_vars.get_default_stream_service():
        raise SageHTTPException(status_code=503, detail="æœåŠ¡æœªé…ç½®æˆ–ä¸å¯ç”¨", error_detail="Stream service is not configured or unavailable")
    
    # éªŒè¯è¯·æ±‚å‚æ•°
    if not request.messages or len(request.messages) == 0:
        raise SageHTTPException(status_code=400, detail="æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    
    logger.info(f"Server: è¯·æ±‚å‚æ•°: {request}")
    
    # æ¸…ç†LLMæ¨¡å‹é…ç½®
    if request.llm_model_config:
        request.llm_model_config = _clean_llm_model_config(request.llm_model_config)

    # è®¾ç½®æµå¼æœåŠ¡
    stream_service, session_id = _setup_stream_service(request)
    
    # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
    db_manager = global_vars.get_database_manager()
    # ç”Ÿæˆæµå¼å“åº”
    async def generate_stream():
        """ç”ŸæˆSSEæµ"""
        try:
            # å‡†å¤‡å’Œæ ¼å¼åŒ–æ¶ˆæ¯
            messages = _prepare_messages(request.messages)
            
            logger.info(f"å¼€å§‹æµå¼å¤„ç†ï¼Œä¼šè¯ID: {session_id}")
            
            # æ·»åŠ æµå¤„ç†è®¡æ•°å™¨å’Œè¿æ¥çŠ¶æ€è·Ÿè¸ª
            stream_counter = 0
            last_activity_time = time.time()
            
            # åˆå§‹åŒ–æ¶ˆæ¯æ”¶é›†å™¨
            message_collector, message_order = _initialize_message_collector(messages)
            
            # å¤„ç†æµå¼å“åº”ï¼Œä¼ é€’æ‰€æœ‰å‚æ•°
            async for result in stream_service.process_stream(
                messages=messages, 
                session_id=session_id,
                user_id=request.user_id,
                deep_thinking=request.deep_thinking,
                max_loop_count=request.max_loop_count,
                multi_agent=request.multi_agent,
                more_suggest=request.more_suggest,
                system_context=request.system_context,
                available_workflows=request.available_workflows,
                force_summary=request.force_summary
            ):
                # æ›´æ–°æµå¤„ç†è®¡æ•°å™¨å’Œæ´»åŠ¨æ—¶é—´
                stream_counter += 1
                current_time = time.time()
                time_since_last = current_time - last_activity_time
                last_activity_time = current_time
                
                # æ¯100ä¸ªç»“æœè®°å½•ä¸€æ¬¡è¿æ¥çŠ¶æ€
                if stream_counter % 100 == 0:
                    logger.info(f"ğŸ“Š æµå¤„ç†çŠ¶æ€ - ä¼šè¯: {session_id}, è®¡æ•°: {stream_counter}, é—´éš”: {time_since_last:.3f}s")

                # æ›´æ–°æ¶ˆæ¯æ”¶é›†å™¨
                _update_message_collector(message_collector,message_order, result)
                
                # å¤„ç†JSONä¼ è¾“ï¼ˆåˆ†å—æˆ–ç›´æ¥å‘é€ï¼‰
                try:
                    async for chunk in _send_chunked_json(result):
                        yield chunk
                except Exception as e:
                    logger.error(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}")
                    # åˆ›å»ºé”™è¯¯å“åº”
                    error_data = {
                        'type': 'error',
                        'message_id': result.get('message_id', 'error'),
                        'content': f'æ•°æ®å¤„ç†é”™è¯¯: {str(e)}',
                        'original_size': len(str(result)),
                        'error': True
                    }
                    yield json.dumps(error_data, ensure_ascii=False) + "\n"
                    
                await asyncio.sleep(0.01)  # é¿å…è¿‡å¿«å‘é€
            
            # å‘é€æµç»“æŸæ ‡è®°
            end_data = {
                'type': 'stream_end',
                'session_id': session_id,
                'timestamp': time.time(),
                'total_stream_count': stream_counter
            }
            total_duration = time.time() - (last_activity_time - time_since_last if 'time_since_last' in locals() else last_activity_time)
            logger.info(f"âœ… å®Œæˆæµå¼å¤„ç†: ä¼šè¯ {session_id}, æ€»è®¡ {stream_counter} ä¸ªæµç»“æœ, è€—æ—¶ {total_duration:.3f}s")
            yield json.dumps(end_data, ensure_ascii=False) + "\n"
            
            # ä¿å­˜ä¼šè¯å’Œæ¶ˆæ¯åˆ°æ•°æ®åº“
            await _save_conversation_if_needed(db_manager, session_id, request)
            await _save_messages_to_db(db_manager, session_id, message_collector, message_order)
                
        except GeneratorExit as ge:
            import sys
            disconnect_msg = f"ğŸ”Œ [GENERATOR_EXIT] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œç”Ÿæˆå™¨è¢«å…³é—­ - ä¼šè¯ID: {session_id}, æ—¶é—´: {time.time()}"
            logger.error(disconnect_msg)
            logger.error(f"ğŸ“Š [GENERATOR_EXIT] æµå¤„ç†ç»Ÿè®¡: å·²å¤„ç† {stream_counter if 'stream_counter' in locals() else 0} ä¸ªæµç»“æœ")
            # å¼ºåˆ¶åˆ·æ–°æ—¥å¿—ç¼“å†²åŒº
            sys.stderr.flush()
            
        except Exception as e:
            logger.error(f"æµå¼å¤„ç†å¼‚å¸¸: {e}")
            logger.error(traceback.format_exc())
            error_data = {
                'type': 'error',
                'message': str(e),
                'session_id': session_id
            }
            yield json.dumps(error_data, ensure_ascii=False) + "\n"
        finally:
            logger.info('æµå¤„ç†ç»“æŸï¼Œæ¸…ç†ä¼šè¯èµ„æº')
            # æ¸…ç†ä¼šè¯èµ„æº
            all_active_sessions_service_map = global_vars.get_all_active_sessions_service_map()
            if session_id in all_active_sessions_service_map:
                del all_active_sessions_service_map[session_id]
            logger.info(f"ä¼šè¯ {session_id} èµ„æºå·²æ¸…ç†")
               
    return StreamingResponse(
        generate_stream(),
        media_type="text/plain"
    )