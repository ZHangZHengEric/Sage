"""
æµå¼èŠå¤©æ¥å£è·¯ç”±æ¨¡å—
"""
import json
import uuid
import asyncio
import traceback
import time
from typing import Dict, Any, Optional, List, Union
from fastapi import APIRouter
from entities.entities import SageHTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from openai import OpenAI

from sagents.tool.tool_proxy import ToolProxy
from sagents.utils.logger import logger
import globals.variables as global_vars

# åˆ›å»ºè·¯ç”±å™¨
stream_router = APIRouter()

class Message(BaseModel):
    role: str
    content: Union[str, List[Dict[str, Any]]]

class StreamRequest(BaseModel):
    messages: List[Message]
    session_id: Optional[str] = None
    user_id: Optional[str] = None
    deep_thinking: Optional[bool] = None
    max_loop_count: Optional[int] = None
    multi_agent: Optional[bool] = None
    more_suggest: Optional[bool] = None
    system_context: Optional[Dict[str, Any]] = None
    available_workflows: Optional[Dict[str, List[str]]] = None
    llm_model_config: Optional[Dict[str, Any]] = None
    system_prefix: Optional[str] = None
    available_tools: Optional[List[str]] = None

    agent_id: Optional[str] = None
    agent_name: Optional[str] = None



    def __init__(self, **data):
        super().__init__(**data)
        # ç¡®ä¿ messages ä¸­çš„æ¯ä¸ªæ¶ˆæ¯éƒ½æœ‰ role å’Œ content
        if self.messages:
            for i, msg in enumerate(self.messages):
                if isinstance(msg, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸º Message å¯¹è±¡
                    self.messages[i] = Message(**msg)
                elif not hasattr(msg, 'role') or not hasattr(msg, 'content'):
                    raise ValueError(f"æ¶ˆæ¯ {i} ç¼ºå°‘å¿…è¦çš„ 'role' æˆ– 'content' å­—æ®µ")



@stream_router.post("/api/stream")
async def stream_chat(request: StreamRequest):
    """æµå¼èŠå¤©æ¥å£"""
    if not global_vars.get_default_stream_service():
        raise SageHTTPException(status_code=503, detail="æœåŠ¡æœªé…ç½®æˆ–ä¸å¯ç”¨", error_detail="Stream service is not configured or unavailable")
    
    logger.info(f"Server: è¯·æ±‚å‚æ•°: {request}")
    # ç”Ÿæˆä¼šè¯ID
    # llm_model_config={'model': '', 'maxTokens': '', 'temperature': ''}
    # å¦‚æœæ˜¯value æ˜¯ç©ºï¼Œåˆ é™¤key
    if request.llm_model_config:
        request.llm_model_config = {k: v for k, v in request.llm_model_config.items() if v is not None and v != ''}

    session_id = request.session_id or str(uuid.uuid4())
    
    # åˆå§‹åŒ–ä¼šè¯æœåŠ¡
    db_manager = global_vars.get_database_manager()

    # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
    existing_conversation = await db_manager.get_conversation(session_id)
    if not existing_conversation:
        # åˆ›å»ºæ–°ä¼šè¯
        if request.messages and len(request.messages) > 0:
            # ä½¿ç”¨ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
            first_message = request.messages[0].content
            if isinstance(first_message, str):
                conversation_title = first_message[:50] + "..." if len(first_message) > 50 else first_message
            elif isinstance(first_message, list) and len(first_message) > 0:
                # å¦‚æœæ˜¯å¤šæ¨¡æ€æ¶ˆæ¯ï¼Œå°è¯•æå–æ–‡æœ¬å†…å®¹
                for item in first_message:
                    if isinstance(item, dict) and item.get('type') == 'text':
                        text_content = item.get('text', '')
                        conversation_title = text_content[:50] + "..." if len(text_content) > 50 else text_content
                        break
        
        await db_manager.save_conversation(
            user_id=request.user_id or "default_user",
            agent_id=request.agent_id or "default_agent",
            agent_name=request.agent_name or "Sage Assistant",
            messages=[msg.model_dump() for msg in request.messages],
            session_id=session_id,
            title=conversation_title
        )
        logger.info(f"åˆ›å»ºæ–°ä¼šè¯: {session_id}, æ ‡é¢˜: {conversation_title}")
    else:
        # æ›´æ–°ç°æœ‰ä¼šè¯çš„æ¶ˆæ¯
        new_messages = [msg.model_dump() for msg in request.messages]
        for msg in new_messages:
            await db_manager.add_message_to_conversation(session_id, msg)
        logger.info(f"æ›´æ–°ç°æœ‰ä¼šè¯: {session_id}")
    
    # åˆ¤æ–­æ˜¯å¦è¦åˆå§‹åŒ–æ–°çš„ sage service è¿˜æ˜¯ä½¿ç”¨é»˜è®¤çš„
    # å–å†³äºæ˜¯å¦éœ€è¦è‡ªå®šä¹‰æ¨¡å‹ä»¥åŠ agent çš„system prefix ï¼Œä»¥åŠå¯¹tool çš„å·¥å…·æ˜¯å¦æœ‰é™åˆ¶
    if request.llm_model_config or request.system_prefix or request.available_tools:
        # æ ¹æ®model config åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯
        server_args = global_vars.get_server_args()
        logger.info(f"åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®api_key :{request.llm_model_config.get('api_key', server_args.default_llm_api_key)}")
        logger.info(f"åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®base_url :{request.llm_model_config.get('base_url', server_args.default_llm_api_base_url)}")
        logger.info(f"åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®model :{request.llm_model_config.get('model', server_args.default_llm_model_name)}")
        model_client = OpenAI(
            api_key=request.llm_model_config.get('api_key', server_args.default_llm_api_key),
            base_url=request.llm_model_config.get('base_url', server_args.default_llm_api_base_url),
        )
        llm_model_config = {
            'model': request.llm_model_config.get('model', server_args.default_llm_model_name)
        }
        
        # åªæœ‰åœ¨æœ‰æœ‰æ•ˆçš„max_tokenså€¼æ—¶æ‰æ·»åŠ è¯¥é”®ï¼Œé¿å…Noneå€¼å¯¼è‡´é”™è¯¯
        max_tokens_value = request.llm_model_config.get('max_tokens', server_args.default_llm_max_tokens)
        max_model_len = request.llm_model_config.get('max_model_len', server_args.default_llm_max_model_len)
        if max_tokens_value is not None:
            llm_model_config['max_tokens'] = int(max_tokens_value)
            
        # åªæœ‰åœ¨æœ‰æœ‰æ•ˆçš„temperatureå€¼æ—¶æ‰æ·»åŠ è¯¥é”®ï¼Œé¿å…Noneå€¼å¯¼è‡´é”™è¯¯
        temperature_value = request.llm_model_config.get('temperature', server_args.default_llm_temperature)
        if temperature_value is not None:
            llm_model_config['temperature'] = float(temperature_value)
        logger.info(f"åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®: {llm_model_config}")

        if request.available_tools:
            logger.info(f"åˆå§‹åŒ–å·¥å…·ä»£ç†ï¼Œå¯ç”¨å·¥å…·: {request.available_tools}")
            start_tool_proxy = time.time()
            # å¦‚æœrequest.multi_agent æ˜¯trueï¼Œè¦ç¡®ä¿request.available_toolsæ²¡æœ‰ complete_task è¿™ä¸ªå·¥å…·
            if request.multi_agent and 'complete_task' in request.available_tools:
                request.available_tools.remove('complete_task')
            tool_proxy = ToolProxy(global_vars.get_tool_manager(), request.available_tools)
            end_tool_proxy = time.time()
            logger.info(f"åˆå§‹åŒ–å·¥å…·ä»£ç†è€—æ—¶: {end_tool_proxy - start_tool_proxy} ç§’")
        else:
            tool_proxy = global_vars.get_tool_manager()

        start_stream_service = time.time()
        # åˆå§‹åŒ–æ–°çš„ sage service
        from handler import SageStreamService
        stream_service = SageStreamService(
            model=model_client,
            model_config=llm_model_config,
            tool_manager=tool_proxy,
            preset_running_config={
                "system_prefix": request.system_prefix
            },
            workspace=server_args.workspace,
            memory_root=server_args.memory_root,
            max_model_len=max_model_len
        )
        end_stream_service = time.time()
        logger.info(f"åˆå§‹åŒ–æµå¼æœåŠ¡è€—æ—¶: {end_stream_service - start_stream_service} ç§’")
        all_active_sessions_service_map = global_vars.get_all_active_sessions_service_map()
        all_active_sessions_service_map[session_id] = {
            'stream_service': stream_service,
            'session_id': session_id,
            "is_default": False
        }
    else:
        logger.info(f"ä½¿ç”¨é»˜è®¤çš„æµå¼æœåŠ¡ï¼Œä¼šè¯ID: {session_id}")
        # ä½¿ç”¨é»˜è®¤çš„ sage service
        stream_service = global_vars.get_default_stream_service()
        # è®°å½•ä¼šè¯ID
        all_active_sessions_service_map = global_vars.get_all_active_sessions_service_map()
        all_active_sessions_service_map[session_id] = {
            'stream_service': stream_service,
            'session_id': session_id,
            "is_default": True
        }
    # ä¿å­˜conversationsè®°å½•
    async def generate_stream(stream_service):
        """ç”ŸæˆSSEæµ"""
        try:
            # ç›´æ¥è½¬æ¢æ¶ˆæ¯æ ¼å¼ï¼Œä¸è¿›è¡Œå†…å®¹è°ƒæ•´
            messages = []
            for msg in request.messages:
                # ä¿æŒåŸå§‹æ¶ˆæ¯çš„æ‰€æœ‰å­—æ®µ
                message_dict = msg.model_dump()
                # å¦‚æœæœ‰content ä¸€å®šè¦è½¬åŒ–æˆstr
                if message_dict.get('content'):
                    message_dict['content'] = str(message_dict['content'])
                messages.append(message_dict)
            
            logger.info(f"å¼€å§‹æµå¼å¤„ç†ï¼Œä¼šè¯ID: {session_id}")
            
            # æ‰“å°è¯·æ±‚ä½“å†…å®¹
            logger.info(f"è¯·æ±‚ä½“å†…å®¹: {request}")
            
            # æ·»åŠ æµå¤„ç†è®¡æ•°å™¨å’Œè¿æ¥çŠ¶æ€è·Ÿè¸ª
            stream_counter = 0
            last_activity_time = time.time()
            
            # åˆå§‹åŒ–æ¶ˆæ¯æ”¶é›†å™¨ï¼Œç”¨äºåˆå¹¶åŸºäºmessage_idçš„æ¶ˆæ¯ï¼Œä¿æŒé¡ºåº
            message_collector = {}  # {message_id: merged_message}
            message_order = []  # ä¿æŒæ¶ˆæ¯çš„åŸå§‹é¡ºåº
            
            # å¤„ç†æµå¼å“åº”ï¼Œä¼ é€’æ‰€æœ‰å‚æ•°
            async for result in stream_service.process_stream(
                messages=messages, 
                session_id=session_id,
                user_id=request.user_id,
                deep_thinking=request.deep_thinking,
                max_loop_count=request.max_loop_count,
                multi_agent=request.multi_agent,
                more_suggest=request.more_suggest,
                system_context=request.system_context,
                available_workflows=request.available_workflows,
                force_summary=global_vars.get_server_args().force_summary
            ):
                # æ›´æ–°æµå¤„ç†è®¡æ•°å™¨å’Œæ´»åŠ¨æ—¶é—´
                stream_counter += 1
                current_time = time.time()
                time_since_last = current_time - last_activity_time
                last_activity_time = current_time
                
                # æ¯100ä¸ªç»“æœè®°å½•ä¸€æ¬¡è¿æ¥çŠ¶æ€
                if stream_counter % 100 == 0:
                    logger.info(f"ğŸ“Š æµå¤„ç†çŠ¶æ€ - ä¼šè¯: {session_id}, è®¡æ•°: {stream_counter}, é—´éš”: {time_since_last:.3f}s")

                # æ”¶é›†æ¶ˆæ¯ç”¨äºåç»­ä¿å­˜åˆ°æ•°æ®åº“
                if isinstance(result, dict) and result.get('message_id'):
                    message_id = result['message_id']
                    
                    # å¦‚æœæ˜¯æ–°æ¶ˆæ¯ï¼Œåˆå§‹åŒ–å¹¶è®°å½•é¡ºåº
                    if message_id not in message_collector:
                        message_collector[message_id] = result
                        # è®°å½•æ¶ˆæ¯çš„åŸå§‹é¡ºåº
                        message_order.append(message_id)
                    # å¯¹äºå·¥å…·è°ƒç”¨ç»“æœæ¶ˆæ¯ï¼Œå®Œæ•´æ›¿æ¢è€Œä¸æ˜¯åˆå¹¶
                    if result.get('role') != 'tool':
                        # åˆå¹¶contentå’Œshow_contentå­—æ®µï¼ˆè¿½åŠ ï¼‰
                        if result.get('content'):
                            message_collector[message_id]['content'] += str(result['content'])
                        if result.get('show_content'):
                            message_collector[message_id]['show_content'] += str(result['show_content'])
                    
            
                # å¤„ç†å¤§JSONçš„åˆ†å—ä¼ è¾“
                try:
                    json_str = json.dumps(result, ensure_ascii=False)
                    json_size = len(json_str)
                    
                    # å¯¹äºè¶…å¤§JSONï¼Œä½¿ç”¨åˆ†å—å‘é€ç¡®ä¿å®Œæ•´æ€§
                    if json_size > 32768:  # 32KBä»¥ä¸Šä½¿ç”¨åˆ†å—å‘é€
                        logger.info(f"ğŸ”„ å¤§JSONåˆ†å—å‘é€: {json_size} å­—ç¬¦")
                        
                        # åˆ†å—å‘é€å¤§JSON
                        chunk_size = 8192  # 8KB per chunk
                        total_chunks = (json_size + chunk_size - 1) // chunk_size
                        
                        # å‘é€åˆ†å—å¼€å§‹æ ‡è®°
                        start_marker = {
                            'type': 'chunk_start',
                            'message_id': result.get('message_id', 'unknown'),
                            'total_size': json_size,
                            'total_chunks': total_chunks,
                            'chunk_size': chunk_size,
                            'original_type': result.get('type', 'unknown')
                        }
                        yield json.dumps(start_marker, ensure_ascii=False) + "\n"
                        await asyncio.sleep(0.01)  # å»¶è¿Ÿç¡®ä¿å‰ç«¯å‡†å¤‡å¥½
                        
                        for i in range(total_chunks):
                            start = i * chunk_size
                            end = min(start + chunk_size, json_size)
                            chunk_data = json_str[start:end]
                            
                            # åˆ›å»ºåˆ†å—æ¶ˆæ¯
                            chunk_message = {
                                'type': 'json_chunk',
                                'message_id': result.get('message_id', 'unknown'),  # æ·»åŠ message_idå­—æ®µ
                                'chunk_id': f"{result.get('message_id', 'unknown')}_{i}",
                                'chunk_index': i,
                                'total_chunks': total_chunks,
                                'chunk_data': chunk_data,
                                'chunk_size': len(chunk_data),
                                'is_final': i == total_chunks - 1,
                                'checksum': hash(chunk_data) % 1000000
                            }
                            
                            yield json.dumps(chunk_message, ensure_ascii=False) + "\n"
                            await asyncio.sleep(0.005)  # é€‚ä¸­å»¶è¿Ÿç¡®ä¿é¡ºåº
                        
                        # å‘é€åˆ†å—ç»“æŸæ ‡è®°
                        end_marker = {
                            'type': 'chunk_end',
                            'message_id': result.get('message_id', 'unknown'),
                            'total_chunks': total_chunks,
                            'expected_size': json_size,
                            'original_type': result.get('type', 'unknown')
                        }
                        yield json.dumps(end_marker, ensure_ascii=False) + "\n"
                        
                        logger.info(f"âœ… å®Œæˆåˆ†å—å‘é€: {total_chunks} å—")
                    else:
                        # å°JSONç›´æ¥å‘é€
                        yield json.dumps(result, ensure_ascii=False) + "\n"
                        
                except Exception as e:
                    logger.error(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}")
                    # åˆ›å»ºé”™è¯¯å“åº”
                    error_data = {
                        'type': 'error',
                        'message_id': result.get('message_id', 'error'),
                        'content': f'æ•°æ®å¤„ç†é”™è¯¯: {str(e)}',
                        'original_size': len(str(result)),
                        'error': True
                    }
                    yield json.dumps(error_data, ensure_ascii=False) + "\n"
                    
                await asyncio.sleep(0.01)  # é¿å…è¿‡å¿«å‘é€
            
            # å‘é€æµç»“æŸæ ‡è®°
            end_data = {
                'type': 'stream_end',
                'session_id': session_id,
                'timestamp': time.time(),
                'total_stream_count': stream_counter
            }
            total_duration = time.time() - (last_activity_time - time_since_last if 'time_since_last' in locals() else last_activity_time)
            logger.info(f"âœ… å®Œæˆæµå¼å¤„ç†: ä¼šè¯ {session_id}, æ€»è®¡ {stream_counter} ä¸ªæµç»“æœ, è€—æ—¶ {total_duration:.3f}s")
            logger.info(f"âœ… æµç»“æŸæ•°æ®: {end_data}")
            yield json.dumps(end_data, ensure_ascii=False) + "\n"
            try:
                # æŒ‰ç…§åŸå§‹é¡ºåºå°†åˆå¹¶çš„æ¶ˆæ¯æ·»åŠ åˆ°ç°æœ‰conversation
                for message_id in message_order:
                    if message_id in message_collector:
                        merged_message = message_collector[message_id]
                        # æ·»åŠ æ¶ˆæ¯åˆ°conversation
                        await db_manager.add_message_to_conversation(session_id, merged_message)
                logger.info(f"æˆåŠŸæŒ‰é¡ºåºä¿å­˜ {len(message_collector)} æ¡æ¶ˆæ¯åˆ°ç°æœ‰conversation {session_id}")
            except Exception as e:
                logger.error(f"ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                
        except GeneratorExit as ge:
            import sys
            disconnect_msg = f"ğŸ”Œ [GENERATOR_EXIT] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œç”Ÿæˆå™¨è¢«å…³é—­ - ä¼šè¯ID: {session_id}, æ—¶é—´: {time.time()}"
            logger.error(disconnect_msg)
            logger.error(f"ğŸ” [GENERATOR_EXIT] GeneratorExitè¯¦æƒ…: {type(ge).__name__} - {str(ge)}")
            logger.error(f"ğŸ“‹ [GENERATOR_EXIT] å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
            logger.error(f"ğŸ“Š [GENERATOR_EXIT] æµå¤„ç†ç»Ÿè®¡: å·²å¤„ç† {stream_counter if 'stream_counter' in locals() else 0} ä¸ªæµç»“æœ")
            # å¼ºåˆ¶åˆ·æ–°æ—¥å¿—ç¼“å†²åŒº
            sys.stdout.flush()
            sys.stderr.flush()
            
        except Exception as e:
            logger.error(f"æµå¼å¤„ç†å¼‚å¸¸: {e}")
            logger.error(traceback.format_exc())
            error_data = {
                'type': 'error',
                'message': str(e),
                'session_id': session_id
            }
            yield json.dumps(error_data, ensure_ascii=False) + "\n"
        finally:
            logger.info('server generate_stream finally save info and delete')
            # æ¸…ç†ä¼šè¯èµ„æº
            all_active_sessions_service_map = global_vars.get_all_active_sessions_service_map()
            if session_id in all_active_sessions_service_map:
                stream_service = all_active_sessions_service_map[session_id]['stream_service']
                if stream_service:
                    if stream_service.save_session(session_id):
                        logger.info(f"ä¼šè¯ {session_id} çŠ¶æ€å·²ä¿å­˜")
                    else:
                        logger.error(f"ä¼šè¯ {session_id} ä¿å­˜å¤±è´¥ï¼Œå·²ç»ä¿å­˜")
                del all_active_sessions_service_map[session_id]
                logger.info(f"ä¼šè¯ {session_id} èµ„æºå·²æ¸…ç†")
    
    return StreamingResponse(
        generate_stream(stream_service),
        media_type="text/plain"
    )