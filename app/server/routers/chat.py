"""
æµå¼èŠå¤©æ¥å£è·¯ç”±æ¨¡å—
"""

import asyncio
import json
import time
import uuid
from typing import Dict, Any, Optional, List, Union
from fastapi import APIRouter, Request
from openai import AsyncOpenAI
from core.exceptions import SageHTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from service.sage_stream_service import SageStreamService
from core.config import StartupConfig, get_startup_config
from loguru import logger
import models
from core.client.llm import get_chat_client
from sagents.tool.tool_manager import get_tool_manager
from sagents.context.session_context import (
    SessionStatus,
    delete_session_run_lock,
    get_session_context,
    get_session_run_lock,
)


# åˆ›å»ºè·¯ç”±å™¨
chat_router = APIRouter()


class Message(BaseModel):
    role: str
    content: Union[str, List[Dict[str, Any]]]


class StreamRequest(BaseModel):
    messages: List[Message]
    session_id: Optional[str] = None
    user_id: Optional[str] = None
    deep_thinking: Optional[bool] = None
    max_loop_count: Optional[int] = None
    multi_agent: Optional[bool] = None
    more_suggest: Optional[bool] = None
    system_context: Optional[Dict[str, Any]] = None
    available_workflows: Optional[Dict[str, List[str]]] = None
    llm_model_config: Optional[Dict[str, Any]] = None
    system_prefix: Optional[str] = None
    available_tools: Optional[List[str]] = None
    force_summary: Optional[bool] = False
    agent_id: Optional[str] = None
    agent_name: Optional[str] = None
    content_beautify: Optional[bool] = True

    def __init__(self, **data):
        super().__init__(**data)
        # ç¡®ä¿ messages ä¸­çš„æ¯ä¸ªæ¶ˆæ¯éƒ½æœ‰ role å’Œ content
        if self.messages:
            for i, msg in enumerate(self.messages):
                if isinstance(msg, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸º Message å¯¹è±¡
                    self.messages[i] = Message(**msg)
                elif not hasattr(msg, "role") or not hasattr(msg, "content"):
                    raise ValueError(f"æ¶ˆæ¯ {i} ç¼ºå°‘å¿…è¦çš„ 'role' æˆ– 'content' å­—æ®µ")


def _clean_llm_model_config(llm_model_config: dict) -> dict:
    """æ¸…ç†LLMæ¨¡å‹é…ç½®ï¼Œç§»é™¤ç©ºå€¼"""
    if not llm_model_config:
        return {}
    return {k: v for k, v in llm_model_config.items() if v is not None and v != ""}


def _build_llm_model_config(request_config: dict, server_args: StartupConfig) -> dict:
    """æ„å»ºLLMæ¨¡å‹é…ç½®"""
    llm_model_config = {
        "model": request_config.get("model", server_args.default_llm_model_name)
    }

    # åªæœ‰åœ¨æœ‰æœ‰æ•ˆçš„max_tokenså€¼æ—¶æ‰æ·»åŠ è¯¥é”®ï¼Œé¿å…Noneå€¼å¯¼è‡´é”™è¯¯
    max_tokens_value = request_config.get(
        "max_tokens", server_args.default_llm_max_tokens
    )
    if max_tokens_value is not None:
        llm_model_config["max_tokens"] = int(max_tokens_value)

    # åªæœ‰åœ¨æœ‰æœ‰æ•ˆçš„temperatureå€¼æ—¶æ‰æ·»åŠ è¯¥é”®ï¼Œé¿å…Noneå€¼å¯¼è‡´é”™è¯¯
    temperature_value = request_config.get(
        "temperature", server_args.default_llm_temperature
    )
    if temperature_value is not None:
        llm_model_config["temperature"] = float(temperature_value)

    return llm_model_config


def _create_model_client(request_config: dict, server_args: StartupConfig):
    model_client = get_chat_client()
    if request_config:
        api_key = request_config.get("apiKey", server_args.default_llm_api_key)
        base_url = request_config.get("baseUrl", server_args.default_llm_api_base_url)
        model_name = request_config.get("model", server_args.default_llm_model_name)
        logger.info(
            f"åˆå§‹åŒ–æ–°çš„æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ¨¡å‹é…ç½®api_key: {api_key}, base_url: {base_url}, model: {model_name}"
        )
        model_client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        model_client.model = model_name
    return model_client


def _create_tool_proxy(request: StreamRequest):
    """åˆ›å»ºå·¥å…·ä»£ç†"""
    if not request.available_tools:
        return get_tool_manager()

    logger.info(f"åˆå§‹åŒ–å·¥å…·ä»£ç†ï¼Œå¯ç”¨å·¥å…·: {request.available_tools}")

    # å¦‚æœrequest.multi_agent æ˜¯trueï¼Œè¦ç¡®ä¿request.available_toolsæ²¡æœ‰ complete_task è¿™ä¸ªå·¥å…·
    if request.multi_agent and "complete_task" in request.available_tools:
        request.available_tools.remove("complete_task")
    from sagents.tool.tool_proxy import ToolProxy

    tool_proxy = ToolProxy(get_tool_manager(), request.available_tools)
    return tool_proxy


def _setup_stream_service(request: StreamRequest):
    """è®¾ç½®æµå¼æœåŠ¡ï¼Œè¿”å›(stream_service, session_id)"""
    session_id = request.session_id or str(uuid.uuid4())
    request.session_id = session_id
    request.llm_model_config = _clean_llm_model_config(request.llm_model_config or {})
    server_args = get_startup_config()
    model_client = _create_model_client(request.llm_model_config, server_args)
    llm_model_config = _build_llm_model_config(request.llm_model_config, server_args)
    max_model_len = request.llm_model_config.get(
        "max_model_len", server_args.default_llm_max_model_len
    )
    # åˆ›å»ºå·¥å…·ä»£ç†
    tool_proxy = _create_tool_proxy(request)
    """åˆ›å»ºæµå¼æœåŠ¡"""
    stream_service = SageStreamService(
        model=model_client,
        model_config=llm_model_config,
        tool_manager=tool_proxy,
        preset_running_config={"system_prefix": request.system_prefix},
        workspace=server_args.workspace,
        memory_root=server_args.memory_root,
        max_model_len=max_model_len,
    )
    return stream_service, session_id


def _prepare_messages(request_messages):
    """å‡†å¤‡å’Œæ ¼å¼åŒ–æ¶ˆæ¯"""
    messages = []
    for msg in request_messages:
        # ä¿æŒåŸå§‹æ¶ˆæ¯çš„æ‰€æœ‰å­—æ®µ
        message_dict = msg.model_dump()
        # å…ˆåˆ¤æ–­åŸæ¶ˆæ¯æ˜¯å¦å­˜åœ¨message_idå­—æ®µï¼Œ ä¸å­˜åœ¨åˆ™åˆå§‹åŒ–ä¸€ä¸ª
        if "message_id" not in message_dict or not message_dict["message_id"]:
            message_dict["message_id"] = str(uuid.uuid4())  # ä¸ºæ¯ä¸ªæ¶ˆæ¯ç”Ÿæˆå”¯ä¸€ID
        # å¦‚æœæœ‰content ä¸€å®šè¦è½¬åŒ–æˆstr
        if message_dict.get("content"):
            message_dict["content"] = str(message_dict["content"])
        messages.append(message_dict)
    return messages


def _initialize_message_collector(messages):
    """åˆå§‹åŒ–æ¶ˆæ¯æ”¶é›†å™¨"""
    message_collector = {}  # {message_id: merged_message}
    message_order = []  # ä¿æŒæ¶ˆæ¯çš„åŸå§‹é¡ºåº

    # å°†è¯·æ±‚çš„messagesæ·»åŠ åˆ°åˆå§‹åŒ–ä¸­
    for msg in messages:
        msg_id = msg["message_id"]
        message_collector[msg_id] = msg
        message_order.append(msg_id)

    return message_collector, message_order


def _update_message_collector(message_collector, message_order, result):
    """æ›´æ–°æ¶ˆæ¯æ”¶é›†å™¨"""
    if not isinstance(result, dict) or not result.get("message_id"):
        return

    message_id = result["message_id"]
    # å¦‚æœæ˜¯æ–°æ¶ˆæ¯ï¼Œåˆå§‹åŒ–
    if message_id not in message_collector:
        message_collector[message_id] = result
        message_order.append(message_id)
    else:
        # å¯¹äºå·¥å…·è°ƒç”¨ç»“æœæ¶ˆæ¯ï¼Œå®Œæ•´æ›¿æ¢è€Œä¸æ˜¯åˆå¹¶
        if result.get("role") != "tool":
            # åˆå¹¶contentå’Œshow_contentå­—æ®µï¼ˆè¿½åŠ ï¼‰
            if result.get("content"):
                message_collector[message_id]["content"] += str(result["content"])
            if result.get("show_content"):
                message_collector[message_id]["show_content"] += str(
                    result["show_content"]
                )


async def _create_conversation_title(request):
    """åˆ›å»ºä¼šè¯æ ‡é¢˜"""
    if not request.messages or len(request.messages) == 0:
        return "æ–°ä¼šè¯"

    # ä½¿ç”¨ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
    first_message = request.messages[0].content
    if isinstance(first_message, str):
        conversation_title = (
            first_message[:50] + "..." if len(first_message) > 50 else first_message
        )
    elif isinstance(first_message, list) and len(first_message) > 0:
        # å¦‚æœæ˜¯å¤šæ¨¡æ€æ¶ˆæ¯ï¼Œå°è¯•æå–æ–‡æœ¬å†…å®¹
        for item in first_message:
            if isinstance(item, dict) and item.get("type") == "text":
                text_content = item.get("text", "")
                conversation_title = (
                    text_content[:50] + "..."
                    if len(text_content) > 50
                    else text_content
                )
                break
        else:
            conversation_title = "å¤šæ¨¡æ€æ¶ˆæ¯"
    else:
        conversation_title = "æ–°ä¼šè¯"

    return conversation_title


async def _ensure_conversation(session_id: str, request: StreamRequest) -> None:
    conversation_dao = models.ConversationDao()
    existing_conversation = await conversation_dao.get_by_session_id(session_id)
    if not existing_conversation:
        conversation_title = await _create_conversation_title(request)
        await conversation_dao.save_conversation(
            user_id=request.user_id or "default_user",
            agent_id=request.agent_id or "default_agent",
            agent_name=request.agent_name or "Sage Assistant",
            messages=[],
            session_id=session_id,
            title=conversation_title,
        )


class ChatRequest(BaseModel):
    messages: List[Message]
    session_id: Optional[str] = None
    user_id: Optional[str] = None
    system_context: Optional[Dict[str, Any]] = None
    agent_id: str

    def __init__(self, **data):
        super().__init__(**data)
        # ç¡®ä¿ messages ä¸­çš„æ¯ä¸ªæ¶ˆæ¯éƒ½æœ‰ role å’Œ content
        if self.messages:
            for i, msg in enumerate(self.messages):
                if isinstance(msg, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸º Message å¯¹è±¡
                    self.messages[i] = Message(**msg)
                elif not hasattr(msg, "role") or not hasattr(msg, "content"):
                    raise ValueError(f"æ¶ˆæ¯ {i} ç¼ºå°‘å¿…è¦çš„ 'role' æˆ– 'content' å­—æ®µ")


@chat_router.post("/api/chat")
async def chat(request: ChatRequest, http_request: Request):
    """æµå¼èŠå¤©æ¥å£"""
    if not get_chat_client():
        raise SageHTTPException(
            status_code=503,
            detail="æ¨¡å‹å®¢æˆ·ç«¯æœªé…ç½®æˆ–ä¸å¯ç”¨",
        )
    # éªŒè¯è¯·æ±‚å‚æ•°
    if not request.messages or len(request.messages) == 0:
        raise SageHTTPException(status_code=400, detail="æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    inner_request = StreamRequest(
        messages=request.messages,
        session_id=request.session_id,
        user_id=request.user_id,
        system_context=request.system_context,
    )
    if request.agent_id:
        agent_dao = models.AgentConfigDao()
        agent = await agent_dao.get_by_id(request.agent_id)
        if agent and agent.config:
            inner_request.agent_name = agent.name or "Sage Assistant"
            inner_request.llm_model_config = agent.config.get("llmConfig", {})
            inner_request.available_tools = agent.config.get("availableTools", [])
            inner_request.available_workflows = agent.config.get("availableWorkflows", {})
            inner_request.deep_thinking = agent.config.get("deepThinking", False)
            inner_request.max_loop_count = agent.config.get("maxLoopCount", 10)
            inner_request.multi_agent = agent.config.get("multiAgent", False)
            inner_request.more_suggest = agent.config.get("moreSuggest", False)
            inner_request.system_context = agent.config.get("systemContext", {})
            inner_request.system_prefix = agent.config.get("systemPrefix", "")
        else:
            raise SageHTTPException(status_code=400, detail=f"Agent ä¸å­˜åœ¨")

    session_id = inner_request.session_id or str(uuid.uuid4())
    inner_request.session_id = session_id
    logger.info(f"sessionId={session_id} Server: è¯·æ±‚å‚æ•°: {inner_request}")
    lock = get_session_run_lock(session_id)
    acquired = False
    if lock.locked():
        ctx = get_session_context(session_id)
        if not ctx or ctx.status != SessionStatus.INTERRUPTED:
            raise SageHTTPException(
                status_code=409,
                detail="ä¼šè¯æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·å…ˆè°ƒç”¨ interrupt æˆ–ä½¿ç”¨ä¸åŒçš„ä¼šè¯ID",
            )
    try:
        await asyncio.wait_for(lock.acquire(), timeout=30)
        acquired = True
    except asyncio.TimeoutError:
        raise SageHTTPException(
            status_code=409,
            detail="ä¼šè¯æ­£åœ¨æ¸…ç†ä¸­ï¼Œè¯·ç¨åé‡è¯•",
        )

    try:
        stream_service, session_id = _setup_stream_service(inner_request)
    except Exception:
        if acquired and lock.locked():
            lock.release()
        raise

    # ç”Ÿæˆæµå¼å“åº”
    async def generate_stream():
        """ç”ŸæˆSSEæµ"""
        try:
            # å‡†å¤‡å’Œæ ¼å¼åŒ–æ¶ˆæ¯
            messages = _prepare_messages(inner_request.messages)

            logger.info(f"sessionId={session_id} å¼€å§‹æµå¼å¤„ç†")
            await _ensure_conversation(session_id, inner_request)

            # æ·»åŠ æµå¤„ç†è®¡æ•°å™¨å’Œè¿æ¥çŠ¶æ€è·Ÿè¸ª
            stream_counter = 0
            last_activity_time = time.time()

            # åˆå§‹åŒ–æ¶ˆæ¯æ”¶é›†å™¨
            message_collector, message_order = _initialize_message_collector(messages)

            # å¤„ç†æµå¼å“åº”ï¼Œä¼ é€’æ‰€æœ‰å‚æ•°
            async for result in stream_service.process_stream(
                messages=messages,
                session_id=session_id,
                deep_thinking=inner_request.deep_thinking,
                max_loop_count=inner_request.max_loop_count,
                multi_agent=inner_request.multi_agent,
                more_suggest=inner_request.more_suggest,
                system_context=inner_request.system_context,
                available_workflows=inner_request.available_workflows,
                force_summary=inner_request.force_summary,
            ):
                # æ›´æ–°æµå¤„ç†è®¡æ•°å™¨å’Œæ´»åŠ¨æ—¶é—´
                stream_counter += 1
                current_time = time.time()
                time_since_last = current_time - last_activity_time
                last_activity_time = current_time

                # æ¯100ä¸ªç»“æœè®°å½•ä¸€æ¬¡è¿æ¥çŠ¶æ€
                if stream_counter % 100 == 0:
                    logger.info(
                        f"ğŸ“Š æµå¤„ç†çŠ¶æ€ - ä¼šè¯: {session_id}, è®¡æ•°: {stream_counter}, é—´éš”: {time_since_last:.3f}s"
                    )

                # æ›´æ–°æ¶ˆæ¯æ”¶é›†å™¨
                _update_message_collector(message_collector, message_order, result)
                # å¯¹å¤–å‘é€çš„å­—æ®µè¿‡æ»¤  ï¼Œ å»é™¤message_type, show_content, is_final, is_chunk
                yield_result = result.copy()
                if "message_type" in yield_result:
                    del yield_result["message_type"]
                if "show_content" in yield_result:
                    del yield_result["show_content"]
                if "is_final" in yield_result:
                    del yield_result["is_final"]
                if "is_chunk" in yield_result:
                    del yield_result["is_chunk"]
                # è·³è¿‡å‘é€token_usageæ¶ˆæ¯
                if yield_result["type"] == "token_usage":
                    continue
                yield json.dumps(yield_result, ensure_ascii=False) + "\n"

                await asyncio.sleep(0.01)  # é¿å…è¿‡å¿«å‘é€

            # å‘é€æµç»“æŸæ ‡è®°
            end_data = {
                "type": "stream_end",
                "session_id": session_id,
                "timestamp": time.time(),
                "total_stream_count": stream_counter,
            }
            total_duration = time.time() - (
                last_activity_time - time_since_last
                if "time_since_last" in locals()
                else last_activity_time
            )
            logger.info(
                f"sessionId={session_id} âœ… å®Œæˆæµå¼å¤„ç†: æ€»è®¡ {stream_counter} ä¸ªæµç»“æœ, è€—æ—¶ {total_duration:.3f}s"
            )
            yield json.dumps(end_data, ensure_ascii=False) + "\n"

        finally:
            logger.info(f"sessionId={session_id} æµå¤„ç†ç»“æŸï¼Œæ¸…ç†ä¼šè¯èµ„æº")
            if acquired and lock.locked():
                lock.release()
            delete_session_run_lock(session_id)
            logger.info(f"sessionId={session_id} èµ„æºå·²æ¸…ç†")

    return StreamingResponse(generate_stream(), media_type="text/plain")
