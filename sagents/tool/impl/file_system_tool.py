import os
import hashlib
import time
from datetime import datetime
from pathlib import Path
import urllib.parse
import re
from typing import Dict, Any, Optional, List
import asyncio

from ..tool_base import tool
from sagents.utils.logger import logger
from sagents.utils.file_system_utils import SecurityValidator, FileMetadata, file_read_core
class FileSystemError(Exception):
    """æ–‡ä»¶ç³»ç»Ÿå¼‚å¸¸"""
    pass

class FileSystemTool:
    """æ–‡ä»¶ç³»ç»Ÿæ“ä½œå·¥å…·é›†"""
  
    @tool(
        description_i18n={
            "zh": "è¯»å–æ–‡æœ¬æ–‡ä»¶æŒ‡å®šè¡ŒèŒƒå›´å†…å®¹",
            "en": "Read text file within a line range",
            "pt": "LÃª conteÃºdo do arquivo em intervalo de linhas"
        },
        param_description_i18n={
            "file_path": {"zh": "æ–‡ä»¶ç»å¯¹è·¯å¾„", "en": "Absolute file path", "pt": "Caminho absoluto do arquivo"},
            "start_line": {"zh": "å¼€å§‹è¡Œå·ï¼Œé»˜è®¤0", "en": "Start line number, default 0", "pt": "Linha inicial, padrÃ£o 0"},
            "end_line": {"zh": "ç»“æŸè¡Œå·ï¼ˆä¸åŒ…å«ï¼‰ï¼Œé»˜è®¤200ï¼ŒNoneè¡¨ç¤ºè¯»å–åˆ°æ–‡ä»¶æœ«å°¾", "en": "End line number (exclusive), default 200, None means read to end", "pt": "Linha final (exclusiva), padrÃ£o 200, None significa ler atÃ© o final"},
            "encoding": {"zh": "æ–‡ä»¶ç¼–ç ï¼Œautoè‡ªåŠ¨æ£€æµ‹", "en": "File encoding, 'auto' for detection", "pt": "CodificaÃ§Ã£o, 'auto' para detectar"},
            "max_size_mb": {"zh": "æœ€å¤§è¯»å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰", "en": "Maximum file size to read (MB)", "pt": "Tamanho mÃ¡ximo do arquivo para leitura (MB)"}
        }
    )
    async def file_read(self, file_path: str, start_line: int = 0, end_line: Optional[int] = 200, 
                  encoding: str = "auto", max_size_mb: float = 10.0) -> Dict[str, Any]:
        """é«˜çº§æ–‡ä»¶è¯»å–å·¥å…·ï¼Œè¯»å–æ–‡æœ¬æ–‡ä»¶ï¼Œä¾‹å¦‚txtï¼Œä»¥åŠé…ç½®æ–‡ä»¶å’Œä»£ç æ–‡ä»¶

        Args:
            file_path (str): æ–‡ä»¶ç»å¯¹è·¯å¾„
            start_line (int): å¼€å§‹è¡Œå·ï¼Œé»˜è®¤0
            end_line (int): ç»“æŸè¡Œå·ï¼ˆä¸åŒ…å«ï¼‰ï¼Œé»˜è®¤200ï¼ŒNoneè¡¨ç¤ºè¯»å–åˆ°æ–‡ä»¶æœ«å°¾
            encoding (str): æ–‡ä»¶ç¼–ç ï¼Œ'auto'è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
            max_size_mb (float): æœ€å¤§è¯»å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤10MB

        Returns:
            Dict[str, Any]: åŒ…å«æ–‡ä»¶å†…å®¹å’Œå…ƒä¿¡æ¯
        """
        
        return await file_read_core(
            file_path=file_path,
            start_line=start_line,
            end_line=end_line,
            encoding=encoding,
            max_size_mb=max_size_mb
        )

    @tool(
        description_i18n={
            "zh": "æŒ‰æ¨¡å¼å†™å…¥æ–‡æœ¬åˆ°æ–‡ä»¶",
            "en": "Write text to file with mode",
            "pt": "Grava texto no arquivo com modo"
        },
        param_description_i18n={
            "file_path": {"zh": "æ–‡ä»¶ç»å¯¹è·¯å¾„", "en": "Absolute file path", "pt": "Caminho absoluto do arquivo"},
            "content": {"zh": "è¦å†™å…¥çš„æ–‡æœ¬å†…å®¹", "en": "Text content to write", "pt": "ConteÃºdo de texto a gravar"},
            "mode": {"zh": "å†™å…¥æ¨¡å¼ overwrite/append/prepend", "en": "Write mode overwrite/append/prepend", "pt": "Modo de gravaÃ§Ã£o overwrite/append/prepend"},
            "encoding": {"zh": "æ–‡ä»¶ç¼–ç ", "en": "File encoding", "pt": "CodificaÃ§Ã£o do arquivo"}
        }
    )
    async def file_write(self, file_path: str, content: str, mode: str = "overwrite", 
                   encoding: str = "utf-8") -> Dict[str, Any]:
        """æ™ºèƒ½æ–‡ä»¶å†™å…¥å·¥å…·

        Args:
            file_path (str): æ–‡ä»¶ç»å¯¹è·¯å¾„
            content (str): è¦å†™å…¥çš„å†…å®¹
            mode (str): å†™å…¥æ¨¡å¼ - 'overwrite', 'append', 'prepend'
            encoding (str): æ–‡ä»¶ç¼–ç ï¼Œé»˜è®¤utf-8
            auto_upload (bool): æ˜¯å¦è‡ªåŠ¨ä¸Šä¼ åˆ°äº‘ç«¯ï¼Œé»˜è®¤True
            
        Returns:
            Dict[str, Any]: æ“ä½œç»“æœå’Œæ–‡ä»¶ä¿¡æ¯
        """
        
        start_time = time.time()
        operation_id = hashlib.md5(f"write_{file_path}_{time.time()}".encode()).hexdigest()[:8]
        logger.info(f"âœï¸ file_writeå¼€å§‹æ‰§è¡Œ [{operation_id}] - æ–‡ä»¶: {file_path}")
        
        try:
            # å®‰å…¨éªŒè¯
            validation = SecurityValidator.validate_path(file_path)
            if not validation["valid"]:
                return {"status": "error", "message": validation["error"]}
            
            file_path = validation["resolved_path"]
            path = Path(file_path)
            
            # åˆ›å»ºç›®å½•ç»“æ„
            if not path.parent.exists():
                path.parent.mkdir(parents=True, exist_ok=True)
            
            # å¤„ç†å†™å…¥æ¨¡å¼
            if mode == "overwrite":
                write_mode = 'w'
                final_content = content
            elif mode == "append":
                write_mode = 'a'
                final_content = content
            elif mode == "prepend":
                write_mode = 'w'
                if path.exists():
                    def read_existing():
                        with open(file_path, 'r', encoding=encoding) as f:
                            return f.read()
                    existing_content = await asyncio.to_thread(read_existing)
                    final_content = content + existing_content
                else:
                    final_content = content
            else:
                return {"status": "error", "message": f"ä¸æ”¯æŒçš„å†™å…¥æ¨¡å¼: {mode}"}
            
            # å†™å…¥æ–‡ä»¶
            write_start_time = time.time()
            
            def write_file():
                with open(file_path, write_mode, encoding=encoding) as f:
                    f.write(final_content)
            
            await asyncio.to_thread(write_file)
            
            write_time = time.time() - write_start_time
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_info = await asyncio.to_thread(FileMetadata.get_file_info, file_path)
            
            result: Dict[str, Any] = {
                "status": "success",
                "message": f"æ–‡ä»¶å†™å…¥æˆåŠŸ ({mode}æ¨¡å¼)",
                "file_info": {
                    "path": file_path,
                    "size_mb": file_info["size_mb"],
                    "encoding": encoding
                },
                "operation": {
                    "mode": mode,
                    "content_length": len(content),
                    "final_content_length": len(final_content),
                    "write_time": write_time,
                    "timestamp": datetime.now().isoformat()
                },
                "operation_id": operation_id
            }
            
            # è‡ªåŠ¨ä¸Šä¼ åˆ°äº‘ç«¯
            # if auto_upload:
            #     try:
            #         upload_result = self.upload_file_to_cloud(file_path)
            #         if upload_result["status"] == "success":
            #             result["cloud_url"] = upload_result["url"]
            #             result["file_id"] = upload_result.get("file_id")
            #             result["message"] += "ï¼Œå·²ä¸Šä¼ åˆ°äº‘ç«¯"
            #         else:
            #             result["upload_error"] = upload_result["message"]
            #     except Exception as e:
            #         result["upload_error"] = f"äº‘ç«¯ä¸Šä¼ å¤±è´¥: {str(e)}"
            
            total_time = time.time() - start_time
            result["execution_time"] = total_time
            
            return result
            
        except Exception as e:
            logger.error(f"ğŸ’¥ æ–‡ä»¶å†™å…¥å¼‚å¸¸ [{operation_id}] - é”™è¯¯: {str(e)}")
            return {"status": "error", "message": f"æ–‡ä»¶å†™å…¥å¤±è´¥: {str(e)}", "operation_id": operation_id}

    @tool(
        description_i18n={
            "zh": "æŒ‰å…³é”®è¯æ£€ç´¢æ–‡ä»¶å¹¶è¿”å›ä¸Šä¸‹æ–‡",
            "en": "Search file by keywords and return context",
            "pt": "Pesquisa por palavras-chave e retorna contexto"
        },
        param_description_i18n={
            "file_path": {"zh": "è¦æœç´¢çš„æ–‡ä»¶è·¯å¾„", "en": "File path to search", "pt": "Caminho do arquivo para buscar"},
            "keywords": {"zh": "å…³é”®è¯åˆ—è¡¨", "en": "List of keywords", "pt": "Lista de palavras-chave"},
            "return_search_item": {"zh": "è¿”å›çš„åŒ¹é…æ¡ç›®æ•°é‡", "en": "Number of matched items to return", "pt": "Quantidade de resultados retornados"}
        }
    )
    def search_content_in_file(self, file_path: str, keywords:list[str],return_search_item=5) -> Dict[str, Any]:
        
        """åœ¨æ–‡ä»¶ä¸­é€šè¿‡å…³é”®è¯åŒ¹é…ï¼Œæœç´¢ç›¸å…³çš„å†…å®¹çš„ä¸Šä¸‹æ–‡å†…å®¹
        Args:
            file_path (str): è¦æœç´¢çš„æ–‡ä»¶è·¯å¾„
            keywords (list[str]): è¦æœç´¢çš„å…³é”®è¯åˆ—è¡¨
            return_search_item (int, optional): è¿”å›çš„æœç´¢ç»“æœæ•°é‡ï¼Œé»˜è®¤5ä¸ª. Defaults to 5.
        Returns:
            Dict[str, Any]: æœç´¢ç»“æœï¼ŒåŒ…å«åŒ¹é…çš„å†…å®¹å’Œä¸Šä¸‹æ–‡
        """
        context_size = 800
        return_search_item = int(return_search_item)
        start_time = time.time()
        operation_id = hashlib.md5(f"search_file_{file_path}_{time.time()}".encode()).hexdigest()[:8]
        logger.info(f"ğŸ” search_content_in_fileå¼€å§‹æ‰§è¡Œ [{operation_id}] - æ–‡ä»¶: {file_path}")
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                return {"status": "error", "message": "æ–‡ä»¶ä¸å­˜åœ¨"}
            
            # è¯»å–æ–‡ä»¶çš„å…¨éƒ¨å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                file_content = f.read()

            # å­˜å‚¨æœç´¢ç»“æœ
            search_results = []
            file_content_lower = file_content.lower()
            
            # æ‰¾åˆ°æ‰€æœ‰å…³é”®è¯çš„åŒ¹é…ä½ç½®
            keyword_positions = {}
            for keyword in keywords:
                keyword_lower = keyword.lower()
                positions = []
                start = 0
                while True:
                    pos = file_content_lower.find(keyword_lower, start)
                    if pos == -1:
                        break
                    positions.append(pos)
                    start = pos + 1
                keyword_positions[keyword] = positions
            
            # æ”¶é›†æ‰€æœ‰åŒ¹é…ä½ç½®å¹¶è®¡ç®—ä¸Šä¸‹æ–‡
            all_positions = []
            for keyword, positions in keyword_positions.items():
                for pos in positions:
                    all_positions.append((pos, keyword))
            
            # æŒ‰ä½ç½®æ’åº
            all_positions.sort()
            
            # åˆå¹¶ç›¸è¿‘çš„åŒ¹é…ä½ç½®ï¼Œé¿å…é‡å¤çš„ä¸Šä¸‹æ–‡
            merged_results: List[Dict[str, Any]] = []
            for pos, keyword in all_positions:
                # è®¡ç®—ä¸Šä¸‹æ–‡èŒƒå›´
                start_char = max(0, pos - context_size // 2)
                end_char = min(len(file_content), pos + context_size // 2)
                
                # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰ç»“æœé‡å 
                overlapped = False
                for existing in merged_results:
                    if (start_char < existing['end_char'] and end_char > existing['start_char']):
                        # åˆå¹¶é‡å åŒºåŸŸ
                        existing['start_char'] = min(existing['start_char'], start_char)
                        existing['end_char'] = max(existing['end_char'], end_char)
                        if keyword not in existing['matched_keywords']:
                            existing['matched_keywords'].append(keyword)
                            existing['score'] += 1
                        overlapped = True
                        break
                
                if not overlapped:
                    # æå–ä¸Šä¸‹æ–‡å†…å®¹
                    context = file_content[start_char:end_char]
                    merged_results.append({
                        'score': 1,
                        'matched_keywords': [keyword],
                        'context': context.strip(),
                        'start_char': start_char,
                        'end_char': end_char,
                        'match_position': pos
                    })
            
            # æŒ‰åˆ†æ•°é™åºæ’åºï¼Œåˆ†æ•°ç›¸åŒæ—¶æŒ‰åŒ¹é…ä½ç½®å‡åº
            merged_results.sort(key=lambda x: (-x['score'], x['match_position']))
            
            # é™åˆ¶è¿”å›ç»“æœæ•°é‡
            search_results = merged_results[:return_search_item]
            
            execution_time = time.time() - start_time
            logger.info(f"âœ… search_content_in_fileæ‰§è¡Œå®Œæˆ [{operation_id}] - è€—æ—¶: {execution_time:.2f}s, æ‰¾åˆ° {len(search_results)} ä¸ªåŒ¹é…é¡¹")
            
            return {
                "status": "success",
                "message": f"æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªåŒ¹é…é¡¹",
                "results": search_results,
                "total_matches": len(search_results),
                "keywords": keywords,
                "execution_time": execution_time,
                "operation_id": operation_id
            }
            
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"æœç´¢æ–‡ä»¶å†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(f"âŒ search_content_in_fileæ‰§è¡Œå¤±è´¥ [{operation_id}] - {error_msg} - è€—æ—¶: {execution_time:.2f}s")
            return {
                "status": "error",
                "message": error_msg,
                "execution_time": execution_time,
                "operation_id": operation_id
            }

    
    @tool(
        description_i18n={
            "zh": "ä»URLä¸‹è½½æ–‡ä»¶åˆ°ç›®å½•",
            "en": "Download file from URL to directory",
            "pt": "Baixa arquivo da URL para diretÃ³rio"
        },
        param_description_i18n={
            "url": {"zh": "è¦ä¸‹è½½çš„æ–‡ä»¶URL", "en": "File URL to download", "pt": "URL do arquivo para download"},
            "working_dir": {"zh": "ä¿å­˜æ–‡ä»¶çš„ç›®å½•", "en": "Directory to save the file", "pt": "DiretÃ³rio para salvar o arquivo"}
        }
    )
    async def download_file_from_url(self, url: str, working_dir: str) -> Dict[str, Any]:
        """ä»URLä¸‹è½½æ–‡ä»¶å¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•

        Args:
            url (str): è¦ä¸‹è½½çš„æ–‡ä»¶URL
            working_dir (str): ä¿å­˜æ–‡ä»¶çš„å·¥ä½œç›®å½•

        Returns:
            Dict[str, Any]: ä¸‹è½½ç»“æœï¼ŒåŒ…å«ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """

        start_time = time.time()
        operation_id = hashlib.md5(f"download_{url}_{time.time()}".encode()).hexdigest()[:8]
        logger.info(f"ğŸ“¥ download_file_from_urlå¼€å§‹æ‰§è¡Œ [{operation_id}] - URL: {url}")
        
        try:
            try:
                import httpx
            except Exception as e:
                return {"status": "error", "message": f"httpxä¸å¯ç”¨: {str(e)}"}
            # æ£€æŸ¥å·¥ä½œç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(working_dir):
                return {"status": "error", "message": f"å·¥ä½œç›®å½•ä¸å­˜åœ¨: {working_dir}"}
            
            # å‘èµ·HTTPè¯·æ±‚ä¸‹è½½æ–‡ä»¶
            download_start_time = time.time()
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.get(url)
                response.raise_for_status()
                content = response.content
            
            download_time = time.time() - download_start_time
            
            # è·å–æ–‡ä»¶å¤§å°
            content_length = len(content)
            content_size_mb = content_length / (1024 * 1024)
            
            # è§£ç URLå¹¶è·å–æ–‡ä»¶å
            decoded_url = urllib.parse.unquote(url)
            file_name = os.path.basename(decoded_url)
            
            # å¦‚æœæ–‡ä»¶åä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
            if not file_name or file_name in ['/', '\\']:
                file_name = f"downloaded_file_{operation_id}"
            
            # æ„å»ºå®Œæ•´æ–‡ä»¶è·¯å¾„
            file_path = os.path.join(working_dir, file_name)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™æ·»åŠ åç¼€
            original_file_path = file_path
            counter = 1
            while os.path.exists(file_path):
                name, ext = os.path.splitext(original_file_path)
                file_path = f"{name}_{counter}{ext}"
                counter += 1
            
            # ä¿å­˜æ–‡ä»¶
            save_start_time = time.time()
            await asyncio.to_thread(lambda: open(file_path, 'wb').write(content))
            save_time = time.time() - save_start_time
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦ä¿å­˜æˆåŠŸ
            if not os.path.exists(file_path):
                return {"status": "error", "message": f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {file_path}"}
            
            saved_size = os.path.getsize(file_path)
            if saved_size != content_length:
                logger.warning(f"âš ï¸ æ–‡ä»¶å¤§å°ä¸åŒ¹é… [{operation_id}] - ä¸‹è½½: {content_length}, ä¿å­˜: {saved_size}")
            
            total_time = time.time() - start_time
            
            return {
                "status": "success",
                "message": "æ–‡ä»¶ä¸‹è½½æˆåŠŸ",
                "file_path": file_path,
                "file_name": file_name,
                "file_size": saved_size,
                "file_size_mb": content_size_mb,
                "download_time": download_time,
                "save_time": save_time,
                "total_time": total_time,
                "operation_id": operation_id
            }
            
        except httpx.HTTPStatusError as e:
            return {"status": "error", "message": f"HTTPé”™è¯¯: {e.response.status_code}"}
        except httpx.RequestError as e:
            return {"status": "error", "message": f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"}
        except Exception as e:
            logger.error(f"ğŸ’¥ ä¸‹è½½å¼‚å¸¸ [{operation_id}] - é”™è¯¯: {str(e)}")
            return {"status": "error", "message": f"ä¸‹è½½å¤±è´¥: {str(e)}"}

    @tool(
        description_i18n={
            "zh": "åœ¨æ–‡ä»¶ä¸­æœç´¢å¹¶æ›¿æ¢æ–‡æœ¬",
            "en": "Search and replace text in file",
            "pt": "Busca e substitui texto no arquivo"
        },
        param_description_i18n={
            "file_path": {"zh": "æ–‡ä»¶ç»å¯¹è·¯å¾„", "en": "Absolute file path", "pt": "Caminho absoluto do arquivo"},
            "search_pattern": {"zh": "è¦æœç´¢çš„æ¨¡å¼æˆ–æ–‡æœ¬", "en": "Pattern or text to search", "pt": "PadrÃ£o ou texto a buscar"},
            "replacement": {"zh": "æ›¿æ¢æ–‡æœ¬", "en": "Replacement text", "pt": "Texto de substituiÃ§Ã£o"},
            "use_regex": {"zh": "æ˜¯å¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼", "en": "Use regular expression", "pt": "Usar expressÃ£o regular"},
            "case_sensitive": {"zh": "æ˜¯å¦åŒºåˆ†å¤§å°å†™", "en": "Case sensitive", "pt": "Diferenciar maiÃºsculas/minÃºsculas"}
        }
    )
    def update_file(self, file_path: str, search_pattern: str, replacement: str, 
                          use_regex: bool = False, case_sensitive: bool = True) -> Dict[str, Any]:
        """æ›´æ–°æ–‡ä»¶ä¸­åŒ¹é…çš„æ–‡æœ¬å†…å®¹

        Args:
            file_path (str): æ–‡ä»¶ç»å¯¹è·¯å¾„
            search_pattern (str): è¦æœç´¢çš„æ¨¡å¼
            replacement (str): æ›¿æ¢æ–‡æœ¬
            use_regex (bool): æ˜¯å¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
            case_sensitive (bool): æ˜¯å¦åŒºåˆ†å¤§å°å†™

        Returns:
            Dict[str, Any]: æ›¿æ¢ç»“æœç»Ÿè®¡
        """
        
        try:
            # å®‰å…¨éªŒè¯
            validation = SecurityValidator.validate_path(file_path)
            if not validation["valid"]:
                return {"status": "error", "message": validation["error"]}
            
            file_path = validation["resolved_path"]
            
            # æ£€æŸ¥æ–‡ä»¶
            file_info = FileMetadata.get_file_info(file_path)
            if not file_info["exists"] or not file_info["is_file"]:
                return {"status": "error", "message": "æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯æœ‰æ•ˆæ–‡ä»¶"}
            
            # è¯»å–æ–‡ä»¶
            encoding = file_info.get("encoding", "utf-8")
            with open(file_path, 'r', encoding=encoding, errors='ignore') as f:
                original_content = f.read()
            
            # æ‰§è¡Œæœç´¢æ›¿æ¢
            if use_regex:
                flags = 0 if case_sensitive else re.IGNORECASE
                pattern = re.compile(search_pattern, flags)
                new_content, replace_count = pattern.subn(replacement, original_content)
            else:
                if case_sensitive:
                    new_content = original_content.replace(search_pattern, replacement)
                    replace_count = original_content.count(search_pattern)
                else:
                    pattern = re.compile(re.escape(search_pattern), re.IGNORECASE)
                    new_content, replace_count = pattern.subn(replacement, original_content)
            
            # å†™å…¥ä¿®æ”¹åçš„å†…å®¹
            with open(file_path, 'w', encoding=encoding, errors='ignore') as f:
                f.write(new_content)
            
            return {
                "status": "success",
                "message": f"æˆåŠŸæ›¿æ¢ {replace_count} å¤„åŒ¹é…é¡¹",
                "statistics": {
                    "replacements": replace_count,
                    "original_length": len(original_content),
                    "new_length": len(new_content),
                    "length_change": len(new_content) - len(original_content)
                }
            }
            
        except re.error as e:
            return {"status": "error", "message": f"æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {str(e)}"}
        except Exception as e:
            return {"status": "error", "message": f"æœç´¢æ›¿æ¢å¤±è´¥: {str(e)}"} 
    
    @tool(
        description_i18n={
            "zh": "å°†CSVè½¬æ¢ä¸ºExcel",
            "en": "Convert CSV to Excel",
            "pt": "Converte CSV para Excel"
        },
        param_description_i18n={
            "csv_file_path": {"zh": "è¾“å…¥CSVæ–‡ä»¶è·¯å¾„", "en": "Input CSV file path", "pt": "Caminho do arquivo CSV de entrada"},
            "excel_file_path": {"zh": "è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„", "en": "Output Excel file path", "pt": "Caminho do arquivo Excel de saÃ­da"}
        }
    )
    def convert_csv_to_excel(self, csv_file_path: str, excel_file_path: str) -> Dict[str, Any]:
        """å°†CSVæ–‡ä»¶è½¬æ¢ä¸ºExcelæ–‡ä»¶

        Args:
            csv_file_path (str): è¾“å…¥çš„CSVæ–‡ä»¶è·¯å¾„
            excel_file_path (str): è¾“å‡ºçš„Excelæ–‡ä»¶è·¯å¾„

        Returns:
            Dict[str, Any]: è½¬æ¢ç»“æœ
        """
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(csv_file_path):
            return {"status": "error", "message": "è¾“å…¥çš„CSVæ–‡ä»¶ä¸å­˜åœ¨"}
        
        # è¯»å–CSVæ–‡ä»¶
        import pandas as pd
        df = pd.read_csv(csv_file_path)
        
        # å†™å…¥Excelæ–‡ä»¶
        df.to_excel(excel_file_path, index=False)
        
        return {
            "status": "success",
            "message": "CSVæ–‡ä»¶å·²æˆåŠŸè½¬æ¢ä¸ºExcelæ–‡ä»¶",
            "excel_file_path": excel_file_path
        }
