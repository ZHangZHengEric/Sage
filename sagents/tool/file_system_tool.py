import os
import shutil
import tempfile
import hashlib
import mimetypes
import logging
import time
from datetime import datetime
from pathlib import Path
import urllib.parse
import requests
import asyncio
import stat
import platform
import zipfile
import tarfile
import re
import chardet
import traceback
from typing import Dict, Any, List, Optional, Union

from .tool_base import ToolBase
from sagents.utils.logger import logger

class FileSystemError(Exception):
    """æ–‡ä»¶ç³»ç»Ÿå¼‚å¸¸"""
    pass

class SecurityValidator:
    """å®‰å…¨éªŒè¯å™¨"""
    
    # å±é™©çš„æ–‡ä»¶æ‰©å±•å
    DANGEROUS_EXTENSIONS = {
        '.exe', '.bat', '.cmd', '.com', '.pif', '.scr', '.vbs', '.js',
        '.jar', '.app', '.deb', '.pkg', '.rpm', '.dmg', '.iso'
    }
    
    # ç³»ç»Ÿå…³é”®ç›®å½•ï¼ˆç¦æ­¢æ“ä½œï¼‰
    PROTECTED_PATHS = {
        '/System', '/usr/bin', '/usr/sbin', '/bin', '/sbin',
        '/Windows/System32', '/Windows/SysWOW64', '/Program Files',
        '/Program Files (x86)'
    }
    
    @staticmethod
    def validate_path(file_path: str, allow_dangerous: bool = False) -> Dict[str, Any]:
        """éªŒè¯æ–‡ä»¶è·¯å¾„çš„å®‰å…¨æ€§"""
        try:
            # æ£€æŸ¥è·¯å¾„éå†æ”»å‡»ï¼ˆåœ¨è§£æå‰æ£€æŸ¥ï¼‰
            if '..' in file_path:
                return {"valid": False, "error": "è·¯å¾„åŒ…å«å±é™©çš„éå†å­—ç¬¦"}
            
            path = Path(file_path).resolve()
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç»å¯¹è·¯å¾„
            if not path.is_absolute():
                return {"valid": False, "error": "å¿…é¡»æä¾›ç»å¯¹è·¯å¾„"}
            
            # æ£€æŸ¥ç³»ç»Ÿä¿æŠ¤ç›®å½•
            path_str = str(path)
            for protected in SecurityValidator.PROTECTED_PATHS:
                if path_str.startswith(protected):
                    return {"valid": False, "error": f"ç¦æ­¢è®¿é—®ç³»ç»Ÿä¿æŠ¤ç›®å½•: {protected}"}
            
            # æ£€æŸ¥å±é™©æ–‡ä»¶æ‰©å±•å
            if not allow_dangerous and path.suffix.lower() in SecurityValidator.DANGEROUS_EXTENSIONS:
                return {"valid": False, "error": f"å±é™©çš„æ–‡ä»¶ç±»å‹: {path.suffix}"}
            
            return {"valid": True, "resolved_path": str(path)}
            
        except Exception as e:
            return {"valid": False, "error": f"è·¯å¾„éªŒè¯å¤±è´¥: {str(e)}"}

class FileMetadata:
    """æ–‡ä»¶å…ƒæ•°æ®ç®¡ç†å™¨"""
    
    @staticmethod
    def get_file_info(file_path: str) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯"""
        try:
            path = Path(file_path)
            
            if not path.exists():
                return {"exists": False}
            
            stat_info = path.stat()
            
            # åŸºç¡€ä¿¡æ¯
            info = {
                "exists": True,
                "name": path.name,
                "absolute_path": str(path.absolute()),
                "size_bytes": stat_info.st_size,
                "size_mb": round(stat_info.st_size / (1024 * 1024), 2),
                "is_file": path.is_file(),
                "is_dir": path.is_dir(),
                "is_symlink": path.is_symlink(),
                "created_time": datetime.fromtimestamp(stat_info.st_ctime).isoformat(),
                "modified_time": datetime.fromtimestamp(stat_info.st_mtime).isoformat(),
                "accessed_time": datetime.fromtimestamp(stat_info.st_atime).isoformat(),
            }
            
            # æ–‡ä»¶ç‰¹å®šä¿¡æ¯
            if path.is_file():
                info.update({
                    "extension": path.suffix.lower(),
                    "mime_type": mimetypes.guess_type(str(path))[0] or "unknown",
                    "encoding": FileMetadata._detect_encoding(file_path) if path.suffix.lower() in ['.txt', '.py', '.js', '.css', '.html', '.md'] else None
                })
            
            # æƒé™ä¿¡æ¯
            info["permissions"] = {
                "readable": os.access(file_path, os.R_OK),
                "writable": os.access(file_path, os.W_OK),
                "executable": os.access(file_path, os.X_OK),
                "mode": oct(stat_info.st_mode)[-3:] if platform.system() != 'Windows' else None
            }
            
            return info
            
        except Exception as e:
            return {"exists": False, "error": str(e)}
    
    @staticmethod
    def _detect_encoding(file_path: str) -> str:
        """æ£€æµ‹æ–‡ä»¶ç¼–ç """
        try:
            with open(file_path, 'rb') as f:
                raw_data = f.read(10000)
                result = chardet.detect(raw_data)
                return result.get('encoding', 'utf-8')
        except Exception:
            return 'utf-8'

class FileSystemTool(ToolBase):
    """æ–‡ä»¶ç³»ç»Ÿæ“ä½œå·¥å…·é›†"""
    
    def __init__(self):
        logger.debug("Initializing FileSystemTool")
        super().__init__()
        self.default_upload_url = "http://36.133.44.114:20034/askonce/api/v1/doc/upload"
        self.default_headers = {"User-Source": 'AskOnce_bakend'}

    @ToolBase.tool()
    def file_read(self, file_path: str, start_line: int = 0, end_line: Optional[int] = None, 
                  encoding: str = "auto", max_size_mb: float = 10.0) -> Dict[str, Any]:
        """é«˜çº§æ–‡ä»¶è¯»å–å·¥å…·

        Args:
            file_path (str): æ–‡ä»¶ç»å¯¹è·¯å¾„
            start_line (int): å¼€å§‹è¡Œå·ï¼Œé»˜è®¤0
            end_line (int): ç»“æŸè¡Œå·ï¼ˆä¸åŒ…å«ï¼‰ï¼ŒNoneè¡¨ç¤ºè¯»å–åˆ°æœ«å°¾
            encoding (str): æ–‡ä»¶ç¼–ç ï¼Œ'auto'è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
            max_size_mb (float): æœ€å¤§è¯»å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤10MB

        Returns:
            Dict[str, Any]: åŒ…å«æ–‡ä»¶å†…å®¹å’Œå…ƒä¿¡æ¯
        """
        start_time = time.time()
        operation_id = hashlib.md5(f"read_{file_path}_{time.time()}".encode()).hexdigest()[:8]
        logger.info(f"ğŸ“– file_readå¼€å§‹æ‰§è¡Œ [{operation_id}] - æ–‡ä»¶: {file_path}")
        
        try:
            # å®‰å…¨éªŒè¯
            validation = SecurityValidator.validate_path(file_path)
            if not validation["valid"]:
                return {"status": "error", "message": validation["error"]}
            
            file_path = validation["resolved_path"]
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_info = FileMetadata.get_file_info(file_path)
            if not file_info["exists"]:
                return {"status": "error", "message": "æ–‡ä»¶ä¸å­˜åœ¨"}
            
            if not file_info["is_file"]:
                return {"status": "error", "message": "æŒ‡å®šè·¯å¾„ä¸æ˜¯æ–‡ä»¶"}
            
            if not file_info["permissions"]["readable"]:
                return {"status": "error", "message": "æ–‡ä»¶æ— è¯»å–æƒé™"}
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if file_info["size_mb"] > max_size_mb:
                return {"status": "error", "message": f"æ–‡ä»¶è¿‡å¤§: {file_info['size_mb']:.2f}MB > {max_size_mb}MB"}
            
            # æ£€æµ‹ç¼–ç 
            if encoding == "auto":
                encoding = file_info.get("encoding", "utf-8")
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding=encoding) as f:
                lines = f.readlines()
            
            # å¤„ç†è¡ŒèŒƒå›´
            total_lines = len(lines)
            if end_line is None:
                end_line = total_lines
            
            start_line = max(0, start_line)
            end_line = min(total_lines, end_line)
            
            if start_line >= total_lines:
                content = ""
            else:
                content = ''.join(lines[start_line:end_line])
            
            total_time = time.time() - start_time
            
            return {
                "status": "success",
                "message": f"æˆåŠŸè¯»å–æ–‡ä»¶ (è¡Œ {start_line}-{end_line})",
                "content": content,
                "file_info": {
                    "path": file_path,
                    "total_lines": total_lines,
                    "read_lines": end_line - start_line,
                    "encoding": encoding,
                    "size_mb": file_info["size_mb"]
                },
                "line_range": {
                    "start": start_line,
                    "end": end_line,
                    "total": total_lines
                },
                "execution_time": total_time,
                "operation_id": operation_id
            }
            
        except UnicodeDecodeError as e:
            return {"status": "error", "message": f"æ–‡ä»¶ç¼–ç é”™è¯¯: {str(e)}ï¼Œè¯·å°è¯•æŒ‡å®šæ­£ç¡®çš„ç¼–ç "}
        except Exception as e:
            logger.error(f"ğŸ’¥ è¯»å–æ–‡ä»¶å¼‚å¸¸ [{operation_id}] - é”™è¯¯: {str(e)}")
            return {"status": "error", "message": f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"}

    @ToolBase.tool()
    def file_write(self, file_path: str, content: str, mode: str = "overwrite", 
                   encoding: str = "utf-8", auto_upload: bool = True) -> Dict[str, Any]:
        """æ™ºèƒ½æ–‡ä»¶å†™å…¥å·¥å…·

        Args:
            file_path (str): æ–‡ä»¶ç»å¯¹è·¯å¾„
            content (str): è¦å†™å…¥çš„å†…å®¹
            mode (str): å†™å…¥æ¨¡å¼ - 'overwrite', 'append', 'prepend'
            encoding (str): æ–‡ä»¶ç¼–ç ï¼Œé»˜è®¤utf-8
            auto_upload (bool): æ˜¯å¦è‡ªåŠ¨ä¸Šä¼ åˆ°äº‘ç«¯ï¼Œé»˜è®¤True
            
        Returns:
            Dict[str, Any]: æ“ä½œç»“æœå’Œæ–‡ä»¶ä¿¡æ¯
        """
        start_time = time.time()
        operation_id = hashlib.md5(f"write_{file_path}_{time.time()}".encode()).hexdigest()[:8]
        logger.info(f"âœï¸ file_writeå¼€å§‹æ‰§è¡Œ [{operation_id}] - æ–‡ä»¶: {file_path}")
        
        try:
            # å®‰å…¨éªŒè¯
            validation = SecurityValidator.validate_path(file_path)
            if not validation["valid"]:
                return {"status": "error", "message": validation["error"]}
            
            file_path = validation["resolved_path"]
            path = Path(file_path)
            
            # åˆ›å»ºç›®å½•ç»“æ„
            if not path.parent.exists():
                path.parent.mkdir(parents=True, exist_ok=True)
            
            # å¤„ç†å†™å…¥æ¨¡å¼
            if mode == "overwrite":
                write_mode = 'w'
                final_content = content
            elif mode == "append":
                write_mode = 'a'
                final_content = content
            elif mode == "prepend":
                write_mode = 'w'
                if path.exists():
                    with open(file_path, 'r', encoding=encoding) as f:
                        existing_content = f.read()
                    final_content = content + existing_content
                else:
                    final_content = content
            else:
                return {"status": "error", "message": f"ä¸æ”¯æŒçš„å†™å…¥æ¨¡å¼: {mode}"}
            
            # å†™å…¥æ–‡ä»¶
            write_start_time = time.time()
            with open(file_path, write_mode, encoding=encoding) as f:
                f.write(final_content)
            write_time = time.time() - write_start_time
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_info = FileMetadata.get_file_info(file_path)
            
            result = {
                "status": "success",
                "message": f"æ–‡ä»¶å†™å…¥æˆåŠŸ ({mode}æ¨¡å¼)",
                "file_info": {
                    "path": file_path,
                    "size_mb": file_info["size_mb"],
                    "encoding": encoding
                },
                "operation": {
                    "mode": mode,
                    "content_length": len(content),
                    "final_content_length": len(final_content),
                    "write_time": write_time,
                    "timestamp": datetime.now().isoformat()
                },
                "operation_id": operation_id
            }
            
            # è‡ªåŠ¨ä¸Šä¼ åˆ°äº‘ç«¯
            if auto_upload:
                try:
                    upload_result = self.upload_file_to_cloud(file_path)
                    if upload_result["status"] == "success":
                        result["cloud_url"] = upload_result["url"]
                        result["file_id"] = upload_result.get("file_id")
                        result["message"] += "ï¼Œå·²ä¸Šä¼ åˆ°äº‘ç«¯"
                    else:
                        result["upload_error"] = upload_result["message"]
                except Exception as e:
                    result["upload_error"] = f"äº‘ç«¯ä¸Šä¼ å¤±è´¥: {str(e)}"
            
            total_time = time.time() - start_time
            result["execution_time"] = total_time
            
            return result
            
        except Exception as e:
            logger.error(f"ğŸ’¥ æ–‡ä»¶å†™å…¥å¼‚å¸¸ [{operation_id}] - é”™è¯¯: {str(e)}")
            return {"status": "error", "message": f"æ–‡ä»¶å†™å…¥å¤±è´¥: {str(e)}", "operation_id": operation_id}

    @ToolBase.tool()
    def upload_file_to_cloud(self, file_path: str) -> Dict[str, Any]:
        """ä¸Šä¼ æ–‡ä»¶åˆ°äº‘ç«¯å­˜å‚¨
        
        Args:
            file_path (str): è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict[str, Any]: ä¸Šä¼ ç»“æœï¼ŒåŒ…å«çŠ¶æ€å’Œæ–‡ä»¶URL
        """
        start_time = time.time()
        operation_id = hashlib.md5(f"upload_cloud_{file_path}_{time.time()}".encode()).hexdigest()[:8]
        logger.info(f"â˜ï¸ upload_file_to_cloudå¼€å§‹æ‰§è¡Œ [{operation_id}] - æ–‡ä»¶: {file_path}")
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                return {"status": "error", "message": "æ–‡ä»¶ä¸å­˜åœ¨"}
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_name = os.path.basename(file_path)
            file_size = os.path.getsize(file_path)
            file_size_mb = file_size / (1024 * 1024)
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶100MBï¼‰
            if file_size > 100 * 1024 * 1024:
                return {"status": "error", "message": "æ–‡ä»¶è¿‡å¤§ï¼Œè¶…è¿‡100MBé™åˆ¶"}
            
            # å‡†å¤‡ä¸Šä¼ 
            url = self.default_upload_url
            headers = self.default_headers
            
            # å‘èµ·ä¸Šä¼ è¯·æ±‚
            upload_start_time = time.time()
            with open(file_path, 'rb') as f:
                files = {'file': (file_name, f, 'application/octet-stream')}
                response = requests.post(url, headers=headers, files=files, timeout=60)
            
            upload_time = time.time() - upload_start_time
            response.raise_for_status()
            
            # å¤„ç†å“åº”
            json_data = response.json()
            file_url = json_data.get('data', {}).get('url')
            file_id = json_data.get('data', {}).get('fileId')
            
            if not file_url:
                return {
                    "status": "error", 
                    "message": "APIè¿”å›æˆåŠŸä½†ç¼ºå°‘æ–‡ä»¶URL",
                    "response": json_data
                }
            
            total_time = time.time() - start_time
            
            return {
                "status": "success", 
                "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ", 
                "url": file_url,
                "file_id": file_id,
                "file_name": file_name,
                "file_size": file_size,
                "file_size_mb": file_size_mb,
                "upload_time": upload_time,
                "total_time": total_time,
                "operation_id": operation_id
            }
                
        except requests.exceptions.Timeout:
            return {"status": "error", "message": "ä¸Šä¼ è¶…æ—¶"}
        except requests.exceptions.RequestException as e:
            return {"status": "error", "message": f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"}
        except Exception as e:
            logger.error(f"ğŸ’¥ ä¸Šä¼ å¼‚å¸¸ [{operation_id}] - é”™è¯¯: {str(e)}")
            return {"status": "error", "message": f"ä¸Šä¼ å¤±è´¥: {str(e)}"}

    @ToolBase.tool()
    def download_file_from_url(self, url: str, working_dir: str) -> Dict[str, Any]:
        """ä»URLä¸‹è½½æ–‡ä»¶å¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•

        Args:
            url (str): è¦ä¸‹è½½çš„æ–‡ä»¶URL
            working_dir (str): ä¿å­˜æ–‡ä»¶çš„å·¥ä½œç›®å½•

        Returns:
            Dict[str, Any]: ä¸‹è½½ç»“æœï¼ŒåŒ…å«ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        start_time = time.time()
        operation_id = hashlib.md5(f"download_{url}_{time.time()}".encode()).hexdigest()[:8]
        logger.info(f"ğŸ“¥ download_file_from_urlå¼€å§‹æ‰§è¡Œ [{operation_id}] - URL: {url}")
        
        try:
            # æ£€æŸ¥å·¥ä½œç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(working_dir):
                return {"status": "error", "message": f"å·¥ä½œç›®å½•ä¸å­˜åœ¨: {working_dir}"}
            
            # å‘èµ·HTTPè¯·æ±‚ä¸‹è½½æ–‡ä»¶
            download_start_time = time.time()
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            download_time = time.time() - download_start_time
            
            # è·å–æ–‡ä»¶å¤§å°
            content_length = len(response.content)
            content_size_mb = content_length / (1024 * 1024)
            
            # è§£ç URLå¹¶è·å–æ–‡ä»¶å
            decoded_url = urllib.parse.unquote(url)
            file_name = os.path.basename(decoded_url)
            
            # å¦‚æœæ–‡ä»¶åä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
            if not file_name or file_name in ['/', '\\']:
                file_name = f"downloaded_file_{operation_id}"
            
            # æ„å»ºå®Œæ•´æ–‡ä»¶è·¯å¾„
            file_path = os.path.join(working_dir, file_name)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™æ·»åŠ åç¼€
            original_file_path = file_path
            counter = 1
            while os.path.exists(file_path):
                name, ext = os.path.splitext(original_file_path)
                file_path = f"{name}_{counter}{ext}"
                counter += 1
            
            # ä¿å­˜æ–‡ä»¶
            save_start_time = time.time()
            with open(file_path, 'wb') as f:
                f.write(response.content)
            save_time = time.time() - save_start_time
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦ä¿å­˜æˆåŠŸ
            if not os.path.exists(file_path):
                return {"status": "error", "message": f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {file_path}"}
            
            saved_size = os.path.getsize(file_path)
            if saved_size != content_length:
                logger.warning(f"âš ï¸ æ–‡ä»¶å¤§å°ä¸åŒ¹é… [{operation_id}] - ä¸‹è½½: {content_length}, ä¿å­˜: {saved_size}")
            
            total_time = time.time() - start_time
            
            return {
                "status": "success",
                "message": "æ–‡ä»¶ä¸‹è½½æˆåŠŸ",
                "file_path": file_path,
                "file_name": file_name,
                "file_size": saved_size,
                "file_size_mb": content_size_mb,
                "download_time": download_time,
                "save_time": save_time,
                "total_time": total_time,
                "operation_id": operation_id
            }
            
        except requests.exceptions.HTTPError as e:
            return {"status": "error", "message": f"HTTPé”™è¯¯: {e.response.status_code}"}
        except requests.exceptions.RequestException as e:
            return {"status": "error", "message": f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"}
        except Exception as e:
            logger.error(f"ğŸ’¥ ä¸‹è½½å¼‚å¸¸ [{operation_id}] - é”™è¯¯: {str(e)}")
            return {"status": "error", "message": f"ä¸‹è½½å¤±è´¥: {str(e)}"}

    @ToolBase.tool()
    def get_file_info(self, file_path: str) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯

        Args:
            file_path (str): æ–‡ä»¶æˆ–ç›®å½•çš„ç»å¯¹è·¯å¾„

        Returns:
            Dict[str, Any]: æ–‡ä»¶è¯¦ç»†ä¿¡æ¯
        """
        try:
            # å®‰å…¨éªŒè¯
            validation = SecurityValidator.validate_path(file_path)
            if not validation["valid"]:
                return {"status": "error", "message": validation["error"]}
            
            file_path = validation["resolved_path"]
            
            # è·å–åŸºç¡€ä¿¡æ¯
            info = FileMetadata.get_file_info(file_path)
            if not info["exists"]:
                return {"status": "error", "message": "æ–‡ä»¶æˆ–ç›®å½•ä¸å­˜åœ¨"}
            
            # ä¸ºå°æ–‡ä»¶æ·»åŠ æ ¡éªŒå’Œ
            if info["is_file"] and info["size_mb"] < 10:
                try:
                    with open(file_path, 'rb') as f:
                        content = f.read()
                    info["checksums"] = {
                        "md5": hashlib.md5(content).hexdigest(),
                        "sha256": hashlib.sha256(content).hexdigest()
                    }
                except Exception as e:
                    info["checksum_error"] = str(e)
            
            return {
                "status": "success",
                "message": "æ–‡ä»¶ä¿¡æ¯è·å–æˆåŠŸ",
                "file_info": info
            }
            
        except Exception as e:
            return {"status": "error", "message": f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}"}

    @ToolBase.tool()
    def search_and_replace(self, file_path: str, search_pattern: str, replacement: str, 
                          use_regex: bool = False, case_sensitive: bool = True) -> Dict[str, Any]:
        """åœ¨æ–‡ä»¶ä¸­æœç´¢å¹¶æ›¿æ¢æ–‡æœ¬

        Args:
            file_path (str): æ–‡ä»¶ç»å¯¹è·¯å¾„
            search_pattern (str): è¦æœç´¢çš„æ¨¡å¼
            replacement (str): æ›¿æ¢æ–‡æœ¬
            use_regex (bool): æ˜¯å¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
            case_sensitive (bool): æ˜¯å¦åŒºåˆ†å¤§å°å†™

        Returns:
            Dict[str, Any]: æ›¿æ¢ç»“æœç»Ÿè®¡
        """
        try:
            # å®‰å…¨éªŒè¯
            validation = SecurityValidator.validate_path(file_path)
            if not validation["valid"]:
                return {"status": "error", "message": validation["error"]}
            
            file_path = validation["resolved_path"]
            
            # æ£€æŸ¥æ–‡ä»¶
            file_info = FileMetadata.get_file_info(file_path)
            if not file_info["exists"] or not file_info["is_file"]:
                return {"status": "error", "message": "æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯æœ‰æ•ˆæ–‡ä»¶"}
            
            # è¯»å–æ–‡ä»¶
            encoding = file_info.get("encoding", "utf-8")
            with open(file_path, 'r', encoding=encoding) as f:
                original_content = f.read()
            
            # æ‰§è¡Œæœç´¢æ›¿æ¢
            if use_regex:
                flags = 0 if case_sensitive else re.IGNORECASE
                pattern = re.compile(search_pattern, flags)
                new_content, replace_count = pattern.subn(replacement, original_content)
            else:
                if case_sensitive:
                    new_content = original_content.replace(search_pattern, replacement)
                    replace_count = original_content.count(search_pattern)
                else:
                    pattern = re.compile(re.escape(search_pattern), re.IGNORECASE)
                    new_content, replace_count = pattern.subn(replacement, original_content)
            
            # å†™å…¥ä¿®æ”¹åçš„å†…å®¹
            with open(file_path, 'w', encoding=encoding) as f:
                f.write(new_content)
            
            return {
                "status": "success",
                "message": f"æˆåŠŸæ›¿æ¢ {replace_count} å¤„åŒ¹é…é¡¹",
                "statistics": {
                    "replacements": replace_count,
                    "original_length": len(original_content),
                    "new_length": len(new_content),
                    "length_change": len(new_content) - len(original_content)
                }
            }
            
        except re.error as e:
            return {"status": "error", "message": f"æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {str(e)}"}
        except Exception as e:
            return {"status": "error", "message": f"æœç´¢æ›¿æ¢å¤±è´¥: {str(e)}"} 